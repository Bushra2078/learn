Well done for getting through all of that! Letâ€™s a have quick recap of what we have covered.

1. Supervised learning is a kind of learning by example: a model makes predictions, they are compared to expected labels, and the model is then updated to produce better results.
1. A cost function is a mathematical way to describe what we want a model to learn. These calculate large numbers when a model is not making good predictions, and small numbers when it is performing well.
1. Gradient descent is an optimization algorithm; a way of calculating how to improve a model, given a cost function and some data.
1. Step size (learning rate) changes how quickly and how well gradient descent performs.
