The way we train models is by no means a perfectly automated process. Training’s blind reliance on data can lead it to learn things that are not actually helpful in the long run (overfit), or to not learn things effectively which are actually useful (underfit). The following learning material walks through some simple reasons why under-fitting and over-fitting take place, and what can be done about it.

## Scenario: Training Avalanche Rescue Dogs

Throughout this module, we’ll be using the following example scenario to explain underfitting and overfitting. This is designed to provide an example for how you might meet these concepts while programming yourself. You should keep in mind, however, this these principles generally apply to almost all types of models, not just those we work with here.

It’s time for your charity to train a new generation of dogs in how to find hikers swept up by avalanches. There is debate in the office as to which dogs are best – is a large dog better than a smaller dog? Should the dogs be trained when they are young or when they are more mature? Thankfully, you have statistics on rescues performed over the last few years that you can look to. Training dogs is expensive though – you need to be sure that your dog-picking criteria are sound.

## Prerequisites

* Familiarity with machine learning models

## Learning objectives

In this module, you will:

* Discover feature normalization – a simple means of improving training
* Create and work with test datasets
* Discover how testing models can both improve and harm training

Unit 1 – Introduction
Unit 2 – Normalization and standardization
Unit 3 – Exercise – Feature normalization
Unit 4 – Test and training datasets
Unit 5 – Exercise - Test and train datasets
Unit 6 – Nuances of test sets
Unit 7 – Exercise – Test set nuances
Unit 8 – Knowledge check
Unit 9 – Summary
