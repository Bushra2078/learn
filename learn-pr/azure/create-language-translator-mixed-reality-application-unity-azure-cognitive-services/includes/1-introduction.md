Suppose you work for a clothing brand as the collaborative tools developer for the Global Expansion team. The team collaborates virtually through a multiuser Mixed Reality application to plan new store openings. This application enables people to work from anywhere in the world. The team spans seven countries and includes individuals who speak various languages. 

As the team prepares to map out product placement and store displays, it finds that the language barrier sometimes results in miscommunication between people. To foster an inclusive work environment, your team needs a speech translation service that can integrate with the collaboration tool.

In this module, you'll create a Mixed Reality application that translates speech to a chosen language. A microphone will capture speech that's sent to the Azure Cognitive Services Speech Translation service. The service will return a string of translated text, which will appear in the application's interface.

By the end of this module, you'll be able to integrate Speech Translation as a feature into a Mixed Reality application.

## Learning objectives

- Configure a Unity project for the Speech service in Azure Cognitive Services
- Integrate the Speech service with a Windows Mixed Reality application
- Use speech recognition to translate text

## Prerequisites

- A Windows 10 PC configured with [the correct tools](https://docs.microsoft.com/windows/mixed-reality/install-the-tools)
- Windows 10 SDK 10.0.18362.0 or later
- Unity Hub with Unity 2019.4.X installed
- Familiarity with [setting up a Unity project for Windows Mixed Reality with the Mixed Reality Toolkit](https://docs.microsoft.com/learn/modules/mixed-reality-toolkit-project-unity/?azure-portal=true)
- Access to a microphone for audio capture
- Basic familiarity with Unity: interface, scene creation, package import, and addition of GameObjects to a scene
- Basic familiarity with C# and Unity scripting
