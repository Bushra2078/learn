Imagine you're part of an analytics team that has recently received a huge assignment of analyzing crime data of several metropolitan cities. The dataset that you received has detailed crime information for major cities. However, each dataset is formatted and structured differently and stored in different data stores. Each city uses a different category and terms for similar type of data. Your team is responsible to analyze all the datasets and report aggregated number of crimes per month in each city.

Your team has decided to leverage the capabilities of Azure Data Factory and Azure Databricks to ingest, transform, and aggregate the required data.

## Learning objectives

In this module, you will:

- Use Azure Data Factory (ADF) to ingest data and create an ADF pipeline.
- Use Copy activities within ADF to copy data from one location to another.
- Use ADF to orchestrate data transformations using a Databricks Notebook activity.

## Pre-requisite

- Azure Subscription: If you don't have an Azure subscription, create a [free account](https://azure.microsoft.com/en-us/free)