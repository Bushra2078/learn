Logging is an essential element of any commercial application. Logging gives you an insight into how, when, where, and why significant events have occurred. It enables you to track the sequence of operations that have led to a particular outcome.

## What is logging?

You use logging to maintain a history of the work done by an application. This information is useful to assist in debugging and analyzing performance problems. The data can provide an insight into the way in which users are interacting with the system. It might help to identify weaknesses, or users attempting to attack the system. Logging can also be used as the basis for an audit trail of activity.

Logging should be unobtrusive, and shouldn't cause you to modify the logical flow of a web application. In its simplest form, you implement logging by printing messages at strategic points in an application. In a web app, you might consider tracking each time a webpage is displayed. If the webpage completes a series of operations, you might also output a message before and after each operation runs. More sophisticated approaches to logging, described later. Here, enable you to customize the way when, how, and where log records are written.

When you add logging to an application, there are several points to consider:

- What information should you record in a log, and in what format? 
  
  The information that you write to a log depends very much on your reason for using logging. If you're using logging to trace the logical flow of progress through the application for debugging purposes, then the data might consist of human-readable text ("Function *x* has started with parameters *y* and *z*"). If the purpose of logging is to track performance, then the information will likely be in some format that can be consumed by the tools you use to analyze that performance. It could be binary, XML, or some other well-defined layout, but it's unlikely to be free-form text. Similarly, your log data might be part of an audit trail, needed to maintain the historical integrity of the chain of events that led to the application being in a given state. Performance and audit data will require tagging with the current date and time.

- Where should the logging output be sent? 

  When debugging a desktop app, you can write messages to the screen, or the Debug window if you're using a tool such as Visual Studio. For a web app hosted in an on-premises server, you can record log data in a local file. However, for a production web app running in an environment such as Azure App Service, you require a repository that's more accessible. You might not have direct access to the file system for the system on which the web app is running. Additionally, if the web app scales out across multiple servers, then writing to the local file system causes the log to become fragmented. 
  
  Security is another concern. A log might contain personal information that should be kept confidential (especially if the log also acts as an audit trail of events). You may also need to ensure that the log can't be tampered with by an unauthorized user. Keeping the log data in a more centralized, secure storage mechanism, such as Azure Blob storage, could be a better and more scalable solution.

- For how long should the messages be saved?

  The lifetime and organization of log data is driven in part by the reason for capturing the information in the first place, as described in the opening point above. If the log is purely for debugging purposes, then the lifetime is likely to be brief; the data can be deleted after the debugging session is complete. If you're capturing data to track performance, after the data has been assimilated, aggregated, and analyzed, it can often be removed or archived. An archive might prove useful for tracking historical performance trends, but can likely be discarded after a short while. Data captured for audit purposes might need to be held indefinitely, subject to the nature of the application, and any regulatory requirements for retaining records. In this case, the repository holding the log data needs to keep an indefinite (and possibly large) amount of data, for a long time.

- In a multiuser system, how do you make sense of the logging output generated by potentially many thousands of concurrent users?

  In a large-scale system, the log messages generated by the interactions of each user with the system will be interwoven, in a large mass of data. To track the path of an individual user or request requires correlation. Each user session must generate a unique key that can be attached to every log message generated by that session. The correlation key domain must support sorting and searching, to enable the data for each individual session to be isolated. 

## Incorporating logging in an ASP.NET web application

One of the most familiar logging mechanisms for .NET developers is implemented by the types in the  **system.diagnostics** namespace. The model used by **system.diagnostics** is based on *listeners*. A listener *listens* for log messages sent by the application, and writes them to a log destination. Listeners are provided for the console, text files, and the event log, among others. You can also update performance counters. In an ASP.NET web application, you configure the listeners in the **web.config** file, and write messages using the methods of the static **System.Diagnostics.Trace** object in your code. Each message is sent to every configured trace listener. For further information, review [Tracing and Instrumenting Applications](https://docs.microsoft.com/dotnet/framework/debug-trace-profile/tracing-and-instrumenting-applications).

If you're building ASP.NET Core web apps, you can use the built-in logging API available in the **Microsoft.Extensions.Logging** namespace. This API works in conjunction with a number of built-in logging providers, each of which send log data to different destinations. The logging framework is extensible, and is also supported by a number of third-party providers. For details, read [Logging in .NET Core and ASP.NET Core](https://docs.microsoft.com/aspnet/core/fundamentals/logging/).

Another approach is to use a third-party logging framework. Many powerful frameworks are available, and they often provide features above and beyond the ones available through the **system.diagnostics** namespace or basic ASP.NET Core logging. Popular logging frameworks for .NET framework applications include [Apache Log4Net](https://logging.apache.org/log4net/), [NLog](https://nlog-project.org/), and [Serilog](https://serilog.net/). 

These frameworks support structured logging, and log levels (as does **system.diagnostics**). Structured logging enables you to write additional system-generated metadata as part of the log message. This data can include a user or session ID, the current date and time, and log message correlation information. Log levels allow you to send log messages to different destinations, depending on the severity of the message. For example, you might want to send all application error messages to a destination that enables you to track issues with your application, and information messages about an operation, to the audit log. You can even selectively turn logging on and off for different log levels. For example, you might want to enable or disable log messages associated with debugging. Logging has an impact on performance, and it's important to reduce these overheads when they aren't required. Most options can be specified by using configuration files rather than having to amend your code.

Different logging frameworks provide drivers for a range of log destinations. As an example, NLog currently provides more than 80 targets, including most of the popular databases. The extensible nature of these frameworks enables developers to add their own custom destinations, and publish drivers for additional targets.

Most logging frameworks use an *appender* model, where data is written to the end (appended) of the target. The meaning of *the end* depends on the target. If the destination is a relational table, an appender will most likely add a new row to the table. If the destination is a file, the appender will add log records to the end of the file. In many cases, you can also configure the appender to implement some form of circular, *rolling* mechanism, whereby you set a maximum size to the destination, and older log records are eventually overwritten. Many appenders provide facilities for compacting and archiving log data before it's overwritten.
