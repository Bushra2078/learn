Suppose you're a software engineer working for a company that runs an amusement park. The company is planning to open a new area in the park soon, and they want to provide the public with an interactive sneak peek at the new experiences offered in this area. 

In most activities within in this area of the park, the visitors will be able to "perform magic" by interacting with their surroundings through spells and wands. The company wants your team to create a VR/AR application that allows future visitors to experience summoning a virtual dragon by saying a spell. The application must be lightweight and easily accessible on the web.

In this module, you will create the core components of this requested application. Your teammates have already set up the BabylonJS project and imported the assets necessary for this application. You will implement the recognition of spells through the Azure Speech-to-text API, enable VR or AR support for the BabylonJS web application, and deploy the application to the public web using Azure Blob Storage.

By the end of this module, you will be able to build and deploy a voice activated BabylonJS WebXR application.

## Learning objectives

- Call the Azure Speech-to-text API through Azure Cognitive Services JavaScript SDK
- Enable VR or AR support in a BabylonJS web app
- Deploy your web app using Static Website Hosting provided by Azure Blob Storage

## Prerequisites

- A computer connected to the internet
- A microphone for capturing audio (can be built in to your computer or external)
- Visual Studio Code
- NodeJS (v14.17.X or above) and npm (v6.14.X or above) installed on your computer
- Basic familiarity with the structure of a BabylonJS project
- Basic familiarity with JavaScript
