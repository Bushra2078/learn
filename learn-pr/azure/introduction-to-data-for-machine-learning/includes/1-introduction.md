Machine learning’s predictive power comes from the fact that it is shaped by data. To make effective models, it is important that you understand what data you are working with.

Here, we explore how data can be categorized, stored, and interpreted both by humans and by computers. We explore what makes a good dataset, and how to fix issues in data that we have. We also practice exploring new data and show how thinking about a dataset more deeply can help to build better predictive models.

## Scenario:

Throughout this module, we’ll be repeatedly referring to the following example scenario. This is designed to provide an example for how you might meet these concepts while programming yourself:

As an eager marine archaeologist, you have an unusually keen interest in maritime disasters. Late one night while scrolling between images of whale bones, and ancient scrolls about Atlantis, you come across a public dataset listing people known to be on the Titanic during its first – and last – voyage. Captured by the balance between fate and chance, you ponder – what were the factors that dictated whether a person survived this famous shipwreck? Data from this period are slightly patchy – a lot of information for certain passengers is unknown. You’ll need to find ways to patch up this data before analyzing it in full.

## Prerequisites
* Familiarity with Python syntax
* A basic understanding of machine learning concepts, such as model and cost

## Learning objectives
In this module, you will:
* Practice generating graphs to explore large datasets
* Learn to identify and correct basic data errors
* Discover how data can be classified and encoded
* Become aware of the factors that that can help – or hurt – the training process