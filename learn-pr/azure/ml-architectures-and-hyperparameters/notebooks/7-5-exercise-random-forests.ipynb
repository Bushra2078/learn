{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd76bd1",
   "metadata": {},
   "source": [
    "* Ready unit 3 (even just the draft) before starting on this unit!\n",
    "* The goal of this unit is the same: to predict who won medals in the olympics\n",
    "* the sport we're focussed on is Rhythmic Gymnastics\n",
    "* the medal column means they won gold, silver, or bronze\n",
    "* Previously was saw how a single decision tree could fit the training data very well but it was very over-fit\n",
    "* The point of /this/ module is to try to avoid the overfitting that we saw with decision tress\n",
    "* We will use random forests, which have already been explained in the content\n",
    "\n",
    "\n",
    "\n",
    "# Exercise: Random forests and model architecture\n",
    "\n",
    "\n",
    "In the previous exercise, we used decision trees to predict whether a Rhythmic Gymnastics athlete would win a medal in the olympics (we did not differentiate between medals).\n",
    "\n",
    "Recall that decision trees could fit the training data very well, but they have a tendency to *overfit*, meaning that the results would degrade considerably when using the *test* set or any *unseen data*.\n",
    "\n",
    "This time we will used *random forests* to address that overfit tendency.\n",
    "\n",
    "We we also look at how the *model's architecture* can influence its performance.\n",
    "\n",
    "## Data visualization and preparation\n",
    "\n",
    "As usual, let's take another quick look at the `olympics` dataset, then split it into *train* and *test* sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec3f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data from the .csv file\n",
    "dataset = pandas.read_csv('olympics.csv', delimiter=\"\\t\")\n",
    "\n",
    "# Remove the male column, which we know is entirely 0s \n",
    "# (There is no male rhythmic gymnastics in the Olympics)\n",
    "del dataset[\"Male\"]\n",
    "\n",
    "#Let's have a look at the data and the relationship we are going to model\n",
    "print(dataset.head())\n",
    "\n",
    "# Split the dataset in an 75/25 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.25, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329695b9",
   "metadata": {},
   "source": [
    "Hopefully this looks familiar to you! If not, jump back and go through the previous exercise on decision trees.\n",
    "\n",
    "## Decision tree\n",
    "\n",
    "Let's quickly train our the previous decision tree to remind ourselves of its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467c4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import recall_score as sensitivity_score\n",
    "\n",
    "# Make a utility method that we can re-use throughout this exercise\n",
    "# To easily fit and test out model\n",
    "def fit_and_test_model(model):\n",
    "    '''\n",
    "    Trains a model and tests it against both train and test sets\n",
    "    '''  \n",
    "\n",
    "    # Define the features that we will use all models\n",
    "    features = [\"Age\", \"Height\", \"Weight\", \"Year\"]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train[features], train.Medal)\n",
    "\n",
    "    # Assess its performance\n",
    "    # -- Train\n",
    "    predictions = model.predict(train[features])\n",
    "    train_sensitivity = sensitivity_score(train.Medal, predictions)\n",
    "\n",
    "    # -- Test\n",
    "    predictions = model.predict(test[features])\n",
    "    test_sensitivity = sensitivity_score(test.Medal, predictions)\n",
    "\n",
    "    return train_sensitivity, test_sensitivity\n",
    "\n",
    "# Fit a tree using max_depth=2, as it yielded the best results in the previous exercise\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# train a decision tree model\n",
    "dt_train_sensitivity, dt_test_sensitivity = fit_and_test_model(model)\n",
    "print(\"Model trained!\")\n",
    "\n",
    "print(\"Train Sensitivity:\", dt_train_sensitivity)\n",
    "print(\"Test Sensitivity:\", dt_test_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a317e9",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "A random forest is a collection of decision trees that work together to calculate the label for a sample.\n",
    "\n",
    "Trees in a random forest are trained independently, on different partitions of data, and thus develop different biases, but when combined they are less likely to overfit the data.\n",
    "\n",
    "Let's build a very simple forest with two tree and the *default* parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98500b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Create a random forest model with two trees\n",
    "random_forest = RandomForestClassifier( n_estimators=2,\n",
    "                                        random_state=2, \n",
    "                                        verbose=False)\n",
    "\n",
    "# Train and test the model\n",
    "train_sensitivity, test_sensitivity = fit_and_test_model(random_forest)\n",
    "\n",
    "print(\"Train Sensitivity:\", train_sensitivity)\n",
    "print(\"Test Sensitivity:\", test_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286f1d2",
   "metadata": {},
   "source": [
    "Our two-tree forest has done more poorly than the single tree on the test set, though has done a better job on the train set. \n",
    "\n",
    "To some extent this should be expected. Random forests usually work with many more trees. Simply having two allowed it to overfit the training data much better than the original decision tree.\n",
    "\n",
    "## Altering the number of trees\n",
    "\n",
    "Let's then build several forest models, each with a different number of trees, and see how they perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a64884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing\n",
    "\n",
    "# n_estimators states how many trees to put in the model\n",
    "# We will make one model for every entry in this list\n",
    "# and see how well each model performs \n",
    "n_estimators = [2, 4, 6, 8, 10, 12, 14,\n",
    "                16, 18, 20, 40, 60, 80, \n",
    "                100, 150, 200, 250, 300,\n",
    "                500]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_sensitivities = []\n",
    "test_sensitivities = []\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    print(\"Preparing a model with\", n_estimator, \"trees\")\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimator, \n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_sensitivity, test_sensitivity = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_sensitivities.append(test_sensitivity)\n",
    "    train_sensitivities.append(train_sensitivity)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D([(\"Train\", lambda x: train_sensitivities), (\"Test\", lambda x: test_sensitivities)], \n",
    "                    n_estimators,\n",
    "                    label_x=\"Numer of estimators (n_estimators)\",\n",
    "                    label_y=\"Sensitivity\",\n",
    "                    title=\"Performance X number of trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50fa9f",
   "metadata": {},
   "source": [
    "The metrics look great for the *training* set, but not so much for the *test* set. In fact, more trees isn't always better - 500 estimators did marginally worse than 100.\n",
    "\n",
    "We can assume this is a result of overtraining due to model complexity.\n",
    "\n",
    "## Altering the minimum number of samples for split parameter\n",
    "\n",
    "Recall that decision trees have a *root node*, *internal nodes* and *leaf nodes*, and that the first two can be split into newer nodes with subsets of data.\n",
    "\n",
    "If we let our model split and create too many nodes, it can become increasingly complex and start to overfit.\n",
    "\n",
    "One way to limit that complexity is to tell the model that each node needs to have __at least__ a certain number of samples, otherwise it can't split into subnodes. \n",
    "\n",
    "In other words, we can set the model's `min_samples_split` parameter to the least number of samples required so that a node can be split.\n",
    "\n",
    "Our default value for `min_samples_split` is only `2`, so models will quickly become too complex if that parameter is left untouched.\n",
    "\n",
    "We will now use the best performing model above, then try it with different `min_samples_split` values and compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of values for the minimun sample splits parameter\n",
    "min_samples_split = np.linspace(2,50,num=(50-2), dtype=int)\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_sensitivities = []\n",
    "test_sensitivities = []\n",
    "\n",
    "# Build models using different values for min_samples_split\n",
    "for min_split in min_samples_split:\n",
    "    print(\"Preparing a model with min_samples_split=\", min_split)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=8, # best result from our first experiment\n",
    "                                min_samples_split=min_split, \n",
    "                                # max_features=None,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "\n",
    "    # Train and test the result\n",
    "    train_sensitivity, test_sensitivity = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_sensitivities.append(test_sensitivity)\n",
    "    train_sensitivities.append(train_sensitivity)\n",
    "\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D([(\"Train\", lambda x: train_sensitivities), (\"Test\", lambda x: test_sensitivities)],\n",
    "                    min_samples_split,\n",
    "                    label_x=\"min_samples_split\",\n",
    "                    label_y=\"Sensitivity\",\n",
    "                    title=\"Performance X minimum number of samples for split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78e429",
   "metadata": {},
   "source": [
    "As you can see above, the more we restrict a model's complexity - by limiting its ability to split nodes - the more we hurt its *training* performance and - up to a point - the more we __increase__ its performance on the *test* set.\n",
    "\n",
    "By limiting the model complexity we address `overfitting`, improving its ability to generalize and make accurate predictions on *unseen* data.\n",
    "\n",
    "Notice that using `min_samples_split=5` gave us the best result for the *test* set, and that higher values did not improve that outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7832359",
   "metadata": {},
   "source": [
    "## Altering the model depth\n",
    "\n",
    "Maybe the results above can still be improved if we experiment with different model parameters?\n",
    "\n",
    "The `model_depth` parameter limits the maximum depth of the trees in a forest. Its default value is `None`, which means nodes can be expanded until all leaves are *pure* (all samples in it have the same label) or have less samples than the value set for `min_samples_split`.\n",
    "\n",
    "Limiting the `model_depth` seems to be a different way to limit a model's complexity.\n",
    "\n",
    "Let's see if we can determine what that \"adequate\" value is by training the most recent model with different variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depths states how deep trees can maximally be expanded\n",
    "# We will make one model for every entry in this list\n",
    "# and see how well each model performs \n",
    "max_depths = np.linspace(2,50,num=(50-2), dtype=int)\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_sensitivities = []\n",
    "test_sensitivities = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    print(\"Preparing a model with max_depth=\", max_depth)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=8, # best result from our first experiment\n",
    "                                min_samples_split=6, # best result from our second experiment\n",
    "                                max_depth=max_depth,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "\n",
    "    # Train and test the results\n",
    "    train_sensitivity, test_sensitivity = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_sensitivities.append(test_sensitivity)\n",
    "    train_sensitivities.append(train_sensitivity)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D([(\"Train\", lambda x: train_sensitivities), (\"Test\", lambda x: test_sensitivities)], \n",
    "                    max_depths,\n",
    "                    label_x=\"max_depths\",\n",
    "                    label_y=\"Sensitivity\",\n",
    "                    title=\"Performance X maximum tree depth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a8cf7",
   "metadata": {},
   "source": [
    "The plot above tells us that our model actually __benefits__ from a higher value for `max_depth`, up to the limit of `11`.\n",
    "\n",
    "The poor results shown by setting this parameter too low suggest that you can actually constrain a model too much and hurt its performance.\n",
    "\n",
    "As usual, it is important to evaluate different values when setting model parameters and defining its architecture.\n",
    "\n",
    "## Our final model\n",
    "After careful study we have improved our random forest model by optimizing three different model params: `n_estimators`, `min_samples_split` and `max_depth`.\n",
    "\n",
    "Let's run our final model using the optimal parameters we learned and compare the results to our original single decision tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fabb7",
   "metadata": {},
   "source": [
    "## Adding some contraints\n",
    "\n",
    "You may have noticed that all of our model have had an argument stating `max_features=None`. This allows trees to train like the original decision tree - all trees can use all features. Let's not use that argument this time, letting the algorithm decide how many features should be available to each tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train our models and report their performance\n",
    "# train_sensitivities = []\n",
    "# test_sensitivities = []\n",
    "\n",
    "# for max_depth in max_depths:\n",
    "#     print(\"Preparing a model with max_depth=\", max_depth)\n",
    "\n",
    "#     # Prepare the model \n",
    "#     rf = RandomForestClassifier(n_estimators=8, # best result from our first experiment\n",
    "#                                 min_samples_split=6, # best result from our second experiment\n",
    "#                                 max_depth=max_depth,\n",
    "#                                 max_features=None,\n",
    "#                                 random_state=2, \n",
    "#                                 verbose=False)\n",
    "    \n",
    "#     # Assess and save its performance\n",
    "#     train_sensitivity, test_sensitivity = fit_and_test_model(rf)\n",
    "#     train_sensitivities.append(train_sensitivity)\n",
    "#     test_sensitivities.append(test_sensitivity)\n",
    "\n",
    "\n",
    "# # Plot results\n",
    "# graphing.line_2D([(\"Train\", lambda x: train_sensitivities), (\"Test\", lambda x: test_sensitivities)], \n",
    "#                     max_depths,\n",
    "#                     label_x=\"max_depths\",\n",
    "#                     label_y=\"Sensitivity\",\n",
    "#                     title=\"Performance X maximum tree depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d18f1",
   "metadata": {},
   "source": [
    "These results are quite different from what we just saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ad3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the best parameters we've found so far\n",
    "rf = RandomForestClassifier(n_estimators=8, # best result from our first experiment\n",
    "                            min_samples_split=6, # best result from our second experiment\n",
    "                            max_depth=14, # best result from our third experiment\n",
    "                            random_state=2, \n",
    "                            verbose=False)\n",
    "\n",
    "# Train the model and save its performance\n",
    "train_sensitivity, test_sensitivity = fit_and_test_model(rf)\n",
    "print(\"train\", train_sensitivity)\n",
    "print(\"test\", test_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee78a60",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "Let's compare the final results to the ones in our single decision tree model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f9097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = {\"Model\": [\"Decision tree\",\"Final random forest\"],\n",
    "        \"Train sensitivity\": [dt_train_sensitivity, train_sensitivity],\n",
    "        \"Test sensitivity\": [dt_test_sensitivity, test_sensitivity],\n",
    "        }\n",
    "\n",
    "df = pandas.DataFrame(cars, columns = [\"Model\", \"Train sensitivity\", \"Test sensitivity\"])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2f6b3",
   "metadata": {},
   "source": [
    "As you can see, fine tuning the model's parameters resulted in a significant improvement in the *test* set results.\n",
    "\n",
    "The lower sensitivity score for the *train* set indicates that the model is not overfitting anymore.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise we covered the following topics:\n",
    "\n",
    "- Random forest models and how they differ from decision trees\n",
    "- How we can change a model's architecture by setting different parameters and changing their values\n",
    "- The importance of trying several combinations of parameters and evaluate these changes to improve performance\n",
    "\n",
    "In the future you will see that different models have architectures where you can fine tune the parameters. Experimentation is needed to achieve the best possible results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
    "kernelspec": {
      "name": "conda-env-py37_default-py",
      "language": "python",
      "display_name": "py37_default"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "conda-env-py37_default-py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
  }