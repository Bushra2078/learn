Data transformation is one of the important aspects of the ETL process. It can be as simple as applying schema to incoming data to restructure it, or of a more complex nature where you perform customized transformation. The complexity of the transformation is based on the type of raw data and the requirements of specific scenario. 

Apache Spark and Azure Databricks provide capabilities to support simple transformation using built-in functions. At the same time, if also gives you an option to use user defined functions to perform customized and complex transformations.

## Clean up

If you plan on completing other Azure Databricks modules, don't delete your Azure Databricks instance yet. You can use the same environment for the other modules.

### Delete the Azure Databricks instance

Navigate to the Azure portal.
Navigate to the Resource Group that contains your Azure Databricks instance.
Select **Delete resource group**.
Type the name of the resource group in the confirmation text box.
Select Delete.