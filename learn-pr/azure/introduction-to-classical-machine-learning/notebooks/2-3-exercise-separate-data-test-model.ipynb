{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e57e33",
   "metadata": {},
   "source": [
    "# Exercise: Supervised Learning\n",
    "\n",
    "Recall our farming scenario, in which we want to look at how January temperatures have changed over time. Here, we'll build a model that achieves this using supervised learning. \n",
    "\n",
    "With many libraries, this can be done in only a few lines of code. Here, we'll break down the process into steps so that we can explore how things are working 'under the hood'.\n",
    "\n",
    "## Four components\n",
    "Recall that there are four key components to supervised learning: the data, the model, the cost function, and the optimiser. Let's inspect these one at a time.\n",
    "\n",
    "### 1. The Data\n",
    "\n",
    "we'll be using publicly available weather data for Seattle. Let's load that and restrict it to January temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64366eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/m0b_optimizer.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/seattleWeather_1948-2017.csv\n",
    "\n",
    "# Load a file containing weather data for seattle\n",
    "data = pandas.read_csv('seattleWeather_1948-2017.csv', parse_dates=['date'])\n",
    "\n",
    "# Keep only January temperatures\n",
    "data = data[[d.month == 1 for d in data.date]].copy()\n",
    "\n",
    "\n",
    "# Print the first and last few rows\n",
    "# Remember that with Jupyter notebooks the last line of \n",
    "# code is automatically printed\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a75848",
   "metadata": {},
   "source": [
    "We have data from 1948 to 2017, split across 2170 rows. \n",
    "\n",
    "we'll be analysing the relationship between `date` and daily minimum temperatures. Let's take a quick look at our data as a graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repository for details\n",
    "\n",
    "# Let's take a quick look at our data\n",
    "graphing.scatter_2D(data, label_x=\"date\", label_y=\"min_temperature\", title=\"January Temperatures (Â°F)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426c775",
   "metadata": {},
   "source": [
    "Machine learning usually works best when the X and Y axes have roughly the same range of values. we'll cover why this is in later learning material. For now, lets just scale our data slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This block of code scales and offsets the data slightly, which helps the training process\n",
    "# You do not need to understand this code. we'll cover these concepts in later learning material\n",
    "\n",
    "# Offset date into number of years since 1982\n",
    "data[\"years_since_1982\"] = [(d.year + d.timetuple().tm_yday / 365.25) - 1982 for d in data.date]\n",
    "\n",
    "# Scale and offset temperature so that it has a smaller range of values\n",
    "data[\"normalised_temperature\"] = (data[\"min_temperature\"] - np.mean(data[\"min_temperature\"])) / np.std(data[\"min_temperature\"])\n",
    "\n",
    "# Graph\n",
    "graphing.scatter_2D(data, label_x=\"years_since_1982\", label_y=\"normalised_temperature\", title=\"January Temperatures (Normalised)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fff6b",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "we'll be selecting a model called a simple linear regression model. This uses a line to make estimates. You might have come across trendlines like these before when making graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442beb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Creates a new MyModel\n",
    "        '''\n",
    "        # Straight lines described by two parameters:\n",
    "        # The slop is the angle of the line\n",
    "        self.slope = 0\n",
    "        # The intercept moves the line up or down\n",
    "        self.intercept = 0\n",
    "\n",
    "    def predict(self, date):\n",
    "        '''\n",
    "        Estimates the temperature from the date\n",
    "        '''\n",
    "        return date * self.slope + self.intercept\n",
    "\n",
    "# Create our model ready to be trained\n",
    "model = MyModel()\n",
    "\n",
    "print(\"Model made!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c1a9f",
   "metadata": {},
   "source": [
    "We wouldn't normally use a model before it has been trained, but for the sake of learning, let's take a quick look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model parameters before training: {model.intercept}, {model.slope}\")\n",
    "\n",
    "# Look at how well the model does before training\n",
    "print(\"Model visualised before training:\")\n",
    "graphing.scatter_2D(data, \"years_since_1982\", \"normalised_temperature\", trendline=model.predict)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689470b1",
   "metadata": {},
   "source": [
    "You can see that before training, our model (the red line) isn't useful at all. It always simply predicts zero.\n",
    "\n",
    "### The objective (cost) function\n",
    "\n",
    "Our next step is to create an _cost function_ (_objective function_).\n",
    "\n",
    "These functions in supervised learning compare the model's estimate to the correct answer. In our case, our label is temperature, so our cost function will compare the estimated temperature to temperatures seen in the historical records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740dd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(actual_temperatures, estimated_temperatures):\n",
    "    '''\n",
    "    Calculates the difference between actual and estimated temperatures\n",
    "    Returns the difference, and also returns the squared difference (the cost)\n",
    "\n",
    "    actual_temperatures: One or more temperatures recorded in the past\n",
    "    estimated_temperatures: Corresponding temperature(s) estimated by the model\n",
    "    '''\n",
    "\n",
    "    # Calculate the difference between actual temperatures and those\n",
    "    # estimated by the model\n",
    "    difference = estimated_temperatures - actual_temperatures\n",
    "\n",
    "    # Convert to a single number that tells us how well the model did\n",
    "    # (smaller numbers are better)\n",
    "    cost = sum(difference ** 2)\n",
    "\n",
    "    return difference, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e840f66",
   "metadata": {},
   "source": [
    "### The optimiser\n",
    "\n",
    "The role of the optimiser is to guess new parameter values for the model. \n",
    "\n",
    "We haven't covered optimisers in detail yet, so to make things simple, will use an pre-written optimiser. You do not need to understand how this works, but if you are curious, you can find it in our GitHub repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from m0b_optimizer import MyOptimizer\n",
    "\n",
    "# Create an optimiser\n",
    "optimizer = MyOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632186a7",
   "metadata": {},
   "source": [
    "## The Training Loop\n",
    "\n",
    "Let's put these components together so that they train the model. \n",
    "\n",
    "Firt, let's make a function that performs one iteration of training. Read each step carefully below. If you would like, add some `print()` statements inside the method, to help you see the training in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1dc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_iteration(model_inputs, true_temperatures, last_cost:float):\n",
    "    '''\n",
    "    Runs a single iteration of training.\n",
    "\n",
    "\n",
    "    model_inputs: One or more dates to provide the model (dates)\n",
    "    true_temperatues: Corresponding temperatures known to occur on from those dates\n",
    "\n",
    "    Returns:\n",
    "        A boolean, as to whether training should continue\n",
    "        The cost calculated (small numbers are better)\n",
    "    '''\n",
    "\n",
    "    # === USE THE MODEL ===\n",
    "    # Estimate temperatures for all data that we have\n",
    "    estimated_temperatures = model.predict(model_inputs)\n",
    "\n",
    "    # === OBJECTIVE FUNCTION ===\n",
    "    # Calculate how well the model is working\n",
    "    # Smaller numbers are better \n",
    "    difference, cost = cost_function(true_temperatures, estimated_temperatures)\n",
    "\n",
    "    # Decide whether to keep training\n",
    "    # we'll stop if the training is no longer improving the model effectively\n",
    "    if cost >= last_cost:\n",
    "        # Abort training\n",
    "        return False, cost\n",
    "    else:\n",
    "        # === OPTIMISER ===\n",
    "        # Calculate updates to parameters\n",
    "        intercept_update, slope_update = optimizer.get_parameter_updates(model_inputs, cost, difference)\n",
    "\n",
    "        # Change the model parameters\n",
    "        model.slope += slope_update\n",
    "        model.intercept += intercept_update\n",
    "\n",
    "        return True, cost\n",
    "\n",
    "print(\"Training method ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7e19b",
   "metadata": {},
   "source": [
    "Let's run a few iterations manually, so that you can watch how training works.\n",
    "\n",
    "Run the code below several times, and note how the model changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "print(f\"Model parameters before training:\\t\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n",
    "\n",
    "continue_loop, cost = train_one_iteration(model_inputs = data[\"years_since_1982\"],\n",
    "                                                    true_temperatures = data[\"normalised_temperature\"],\n",
    "                                                    last_cost = math.inf)\n",
    "\n",
    "print(f\"Model parameters after 1 iteration of training:\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c66e0d",
   "metadata": {},
   "source": [
    "It will take thousands of iterations to train the model well, so let's wrap it in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300a1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# start the loop\n",
    "print(\"Training beginning...\")\n",
    "last_cost = math.inf\n",
    "i = 0\n",
    "continue_loop = True\n",
    "while continue_loop:\n",
    "\n",
    "    # Run one iteration of training\n",
    "    # This will tell us whether to stop training, and also what\n",
    "    # the cost was for this iteration\n",
    "    continue_loop, last_cost = train_one_iteration(model_inputs = data[\"years_since_1982\"],\n",
    "                                                    true_temperatures = data[\"normalised_temperature\"],\n",
    "                                                    last_cost = last_cost)\n",
    "   \n",
    "    # Print the status\n",
    "    if i % 400 == 0:\n",
    "        print(\"Iteration:\", i)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "print(\"Training complete!\")\n",
    "print(f\"Model parameters after training:\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n",
    "graphing.scatter_2D(data, \"years_since_1982\", \"normalised_temperature\", trendline=model.predict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994939d",
   "metadata": {},
   "source": [
    "Notice how now the model is trained, it's giving more sensible predictions about January temperatures.\n",
    "\n",
    "Interestingly, the model shows temperatures going up over time. Perhaps we need to stop feeding grain to our elk earlier in the year!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, we split up supervised learning into its individual stages to see what is going on 'under the hood' when we use 3rd party libraries. The important point to take away is how these pieces integrate together. In particular, how data is required by most parts of this process."
   ]
  }
 ],
"metadata": {
  "kernelspec": {
    "name": "conda-env-py37_default-py",
    "language": "python",
    "display_name": "py37_default"
  },
  "language_info": {
    "name": "python",
    "version": "3.7.9",
    "mimetype": "text/x-python",
    "codemirror_mode": {
      "name": "ipython",
      "version": 3
    },
    "pygments_lexer": "ipython3",
    "nbconvert_exporter": "python",
    "file_extension": ".py"
  },
  "kernel_info": {
    "name": "conda-env-py37_default-py"
  },
  "nteract": {
    "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
