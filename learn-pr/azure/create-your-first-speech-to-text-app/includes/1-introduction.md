Suppose you're a developer who works for a medical transcription company. Your company's clients are a team of doctors who record their notes as audio files on handheld digital voice recorders. They share their files with your company through a shared cloud drive, and their notes are combination of short memos and longer dictations.

Your company has to maintain a large staff of transcribers, and these two types of audio files present interesting challenges for your company:

- Your company's transcribers require a great deal of time to process the volume of short memos from your clients, so it is difficult for your company to return the transcriptions within the timeframe that is defined in your company's service level agreement.

- The longer dictations often cannot be transcribed in a single session, and your company's transcribers have difficultly remembering where they left off during their previous session.

You've heard that Microsoft's Azure Cognitive Services provide developers with APIs to create applications that take advantage of Azure's speech-to-text features, and your manager has asked you to research a way where you can use Azure Cognitive Services' speech-to-text features to create an application that you can use to offset some of the transcription tasks, thereby alleviating some of your operating costs and service level agreement issues.

In this module, you'll learn how to use Azure Cognitive Services to create a speech-to-text application that converts a sample WAVE file into text.

## Learning objectives

In this module, you'll:

- Create an Azure Cognitive Services account
- Create a command-line application that uses single-shot recognition to convert speech to text
- Create a command-line application that uses continuous recognition to convert speech to text

## Prerequisites

- Basic familiarity with development tools
