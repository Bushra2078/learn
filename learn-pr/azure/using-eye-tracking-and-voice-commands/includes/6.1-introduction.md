The Mixed Reality Toolkit enables you to consume inputs from various input sources such as 6DoF (degrees of freedom) controllers, articulated hands, or speech. Choosing the interaction model best suited for your mixed reality experience requires you to identify your user, their goals and consider any situational or environmental factors that may impact their experience.

Suppose say you're designing a game that requires a lot of interactions. The users are a bit concerned about the method of interaction as it will be tiring to use the controllers over a long period. Therefore, you need to come up with alternative methods of input for the success of your application.

This module shows you how to incorporate eye-tracking and voice commands with MRTK using NASA's Mars Curiosity Rover hologram model. Here, you'll:

* How to enable eye-tracking for HoleLens 2
* Learn how to use eye-tracking to trigger action
* How to create speech commands
* Learn how to control speech commands globally and locally

By the end of the module, you can add eye-tracking and voice commands to your project using MRTK.
