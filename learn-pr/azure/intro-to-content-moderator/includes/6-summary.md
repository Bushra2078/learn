Content moderation is a process that involves simple steps. Reviewing, monitoring, and interpretation of content before it is displayed or released for general consumption. 

The Azure Content Moderator service can help your organization review text, image, and video content. Use the service to ensure content does not contain objectionable material. The built-in capabilities to incorporate human review into the process is an advantage that can add an extra layer of validation.

Use the Azure Content Moderator service for situations that would require a content moderation service such as:

- Online marketplaces that moderate product catalogs and other user-generated content.
- Gaming companies that moderate user-generated game artifacts and chat rooms.
- Social messaging platforms that moderate images, text, and videos added by their users.
