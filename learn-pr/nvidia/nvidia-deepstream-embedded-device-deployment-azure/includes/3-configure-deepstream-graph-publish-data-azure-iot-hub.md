Azure IoT Hub is a managed service in the Azure cloud that provides secure registration for IoT devices to allow for high-throughput communication from your device to the cloud and from the cloud to your device. You'll use this resource to register an NVIDIA embedded device and configure it with a DeepStream-based IoT Edge deployment.

1. Complete the steps in the [Quickstart: Create an IoT hub using the Azure portal](/azure/iot-hub/iot-hub-create-through-portal#create-an-iot-hub). You need to follow the steps only in the section **Create an IoT hub**. The other steps that are described in the documentation are optional. When you've finished this task, you can proceed with the next step.

1. NVIDIA DeepStream supports integration with Azure IoT Edge through [Azure MQTT protocol adapter libraries](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html#azure-mqtt-protocol-adapter-libraries). The libraries extend the [Gst-nvmsbroker](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html#) plugin that's in the DeepStream SDK. Through the Azure protocol adapter, DeepStream applications can publish messages directly to an IoT hub in Azure by using the MQTT protocol.

    Complete the following steps on an x86-based host machine that has the DeepStream 6.0 Graph Composer installed. The steps assume that you've completed the steps described in the previous modules, **Set up and configuration an NVIDIA DeepStream development environment** and **Introduction to DeepStream 6.0 Graph Composer with Microsoft Azure**.

1. In the Graph Composer application, select **File** > **Open Graph**. Go to */opt/nvidia/deepstream/deepstream/reference_graphs/deepstream-test4* and select the *deepstream-test4.yaml* file. Then, select **Okay**.

    :::image type="content" source="../media/composer-open-test.png" alt-text="Screenshot that shows opening the DeepStream Test4 application in Graph Composer." lightbox="../media/composer-open-test4.png":::

    This sample builds on top of the earlier *deepstream-test1* graph to demonstrate how to send inference output messages to the cloud.

    :::image type="content" source="../media/composer-test.png" alt-text="Screenshot of the opened DeepStream Test4 application in Graph Composer." lightbox="../media/composer-test4.png":::

    The graph contains more `NvDsSampleProbeMessageMetaCreation` and `NvDsMsgConvBroker` components, which together are responsible for sending messages to the cloud. The `NvDsSampleProbeMessageMetaCreation` transforms the metadata that's generated by the pipeline into another metadata of type `NVDS_EVENT_MSG_DATA`. This metadata is serialized by `NvDsMsgConvBroker` and then sent to the cloud via a message broker protocol.

1. To modify this sample to publish to the Azure cloud, update the `msg-conv-config` property of the `NvDsMsgConvBroker`. Change the property from */opt/nvidia/deepstream/deepstream/lib/libnvds_kafka_proto.so* to */opt/nvidia/deepstream/deepstream/lib/libnvds_azure_edge_proto.so*. This change configures the output to use the Azure protocol adapter that ships with the DeepStream SDK.
