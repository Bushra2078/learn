In this module, you learned how to:

- Create an NVIDIA GPU Accelerated Virtual Machine
- Configure NVIDIA Triton Inference Server and related prerequisites
- Execute an inference workload on NVIDIA Triton Inference Server

## Summary

The development team has successfully implemented a full custom object detection solution in their line of business.  The team used Azure Machine Learning studio to operationalize the gathering and tagging of image samples.  They were also able to streamline the ability to train new models using GPU accelerated compute instances.  Now they've concluded the project by deploying their model to an NVIDIA Triton Inference Server and verified that the model is now ready to go into production at the manufacturing site.