In this module, you learned how to:

- Create an NVIDIA GPU Accelerated Virtual Machine
- Configure NVIDIA Triton Inference Server and related prerequisites
- Execute an inference workload on NVIDIA Triton Inference Server
