Transparency is an important principle in ethical AI. It supports other AI principles, including:

:::image type="icon" source="../media/use-transparency-principle.png":::

**Accountability**: Allows oversight organizations to check algorithms for problems, assess how well the system works, and determine who is accountable.

**Fairness**: Prevents unfair discrimination by requiring systems to validate their decisions and demonstrate fair treatment of different groups.

Transparency emphasizes the importance of making AI systems easy to understand. This involves creators explaining how their AI systems work, why they work that way, and being honest about capabilities and limitations. Achieving transparency builds trust, especially as AI becomes more integrated into our daily lives. Transparency means:

**Explicability** Creators of AI systems should provide clear explanations of how the system functions and makes choices. Technical details and corporate secrecy should not obscure these processes. For instance, a virtual assistant should openly explain how it processes voice commands and what it does with that information to carry out tasks. This kind of openness makes it easier for people to trust and make sense of AI systems.

**Justification**. It is important for the creators of AI systems to be able to explain why they designed them the way they did. For example, in the context of a recommendation system on a streaming platform, it should be able to clarify why it suggests specific movies or songs. For instance, it might mention that it recommended a particular song based on the user's listening history. This kind of transparency assists in comprehending and having confidence in the system.

**Honesty**. AI creators should provide transparent information regarding their system's capabilities and limitations. When considering a health monitoring app, the app's creator should be truthful about what it can and cannot do. For example, if the app is not accurate in measuring certain health parameters, it should openly acknowledge these limitations. This transparency empowers individuals to make informed decisions.

**Auditability**. AI systems should possess logging, reporting, and auditing capabilities to monitor their operations, identify errors, detect biases, and facilitate oversight. Let's take a credit scoring AI system as an example. It should keep a record of how it evaluates creditworthiness and the factors it considers. This record enables auditors to review its decisions and ensure fairness and accuracy in assessing individuals' credit. This practice helps confirm that AI systems are functioning responsibly.

## Ensuring transparency in AI

By ensuring that the AI systems you use are transparent, you can better understand how they work and generate informed decisions. This can help you promote trust, accountability, fairness, safety, and inclusiveness while using AI in education. Here are some key points to ensure transparency in the AI systems you use:

- Look for systems that are accompanied by documentation of characteristics of their datasets to help developers understand if a specific dataset is appropriate for their use case.

- Ensure that employees who interpret the output from AI are trained in how to do so and remain accountable for making consequential decisions based on the results.

:::image type="icon" source="../media/ensuring-transparency-in-ai.png":::

Grasping the essence of transparency in AI is merely the first step. As we move beyond transparency, itâ€™s essential to understand that it is deeply connected with accountability. These elements are not standalone; they are connected. In the next unit, you will explore the principle of accountability, examining how this principle is crucial to ensuring that AI systems are not just transparent but also adhere to the highest standards of ethical responsibility and answerability in every situation.
