The underlying infrastructure of the cloud (or the datacenter) might consist of thousands of processors connected to terabytes of memory and petabytes of disk capacity. Often, there is a mismatch between the ideal number of processors a certain application requires and the actual number of physical processors available. It is more frequently the case that an application cannot exploit more than a fraction of the processors available due to two main limitations:

- Availability of parallelism in the application
- Amenability of the application to scale well with more processors

These limitations led to the examination of techniques that can help utilize hardware resources more effectively. Resource sharing is one of these techniques.

## Resource sharing in space and time

Resource sharing refers to multiplexing or partitioning system resources (for example, CPUs, memory) among application processes. Resource sharing is not a new idea. It has been applied traditionally to uniprocessor and multiprocessor systems via the OS. Typically, there are two ways to implement resource sharing, either in space or in time. Sharing in time (or timesharing) allows processes to take turns using a resource component while sharing in space enables each process to have exclusive access to a specific portion of a component. For instance, with a single CPU and multiple processes, the OS can allocate the CPU to each process for a certain time interval under the rule that only one process can run at a time on the CPU, which can be achieved by using a specific CPU scheduling mechanism. The part of the OS that performs scheduling, or more precisely, that decides which process runs next on the CPU, is called the scheduler. The strategy that the scheduler uses for multiplexing between processes is called the scheduling algorithm. One popular strategy for scheduling processes on a CPU is the round-robin algorithm (see Figure 7). With round-robin, each process is assigned a time interval (or a quantum) during which it is allowed to execute. The OS can maintain a queue of processes, as shown in Figure 7(a). When a process is scheduled on a CPU and it completes execution for its time quantum, it gets preempted and added to the tail of waiting processes. The process at the head of the queue is then granted to run on the CPU, as depicted in Figure 7(b). This is also called _context switching_.

![Round-robin scheduling. (a) A queue of processes, with the process at the head. Process A is currently scheduled at a CPU, and the one next to it, B, is ready to get running once A is context-switched. (b) The queue when A uses up its quantum, gets context-switched, and B gets scheduled.](../media/round-robin-scheduling.png)

_Figure 7: Round-robin scheduling. (a) A queue of processes, with the process at the head. Process A is currently scheduled at a CPU, and the one next to it, B, is ready to get running once A is context-switched. (b) The queue when A uses up its quantum, gets context-switched, and B gets scheduled._

As mentioned previously, resource sharing can be achieved in space, as well. A common example of sharing in space is sharing the main memory. The main memory usually is partitioned into multiple partitions, each allocated to a process. Thus, the data of all processes will be resident in the memory at the same time. Sharing memory in space makes the system more efficient than allocating the whole memory to a single process. In particular, it allows each process to take turns on the CPU in a much faster way (because it is faster to load the process state from the main memory than from disk). Another common example of sharing in space is sharing disk storage, in which a disk can hold files from multiple users at the same time. Partitioning memory and disk spaces, as well as keeping track of who is using which memory portion and which disk blocks are typical OS tasks. The OS abstracts system components, so resource sharing is eased. For instance, rather than having to worry about sharing the tracks, sectors, cylinders, and bandwidth of a disk drive, we simply deal with files.

<!-- Reference listed in original course not cited in the unit. -->
