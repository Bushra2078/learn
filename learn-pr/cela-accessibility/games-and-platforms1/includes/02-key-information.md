Another foundational accessibility concept is related to the portrayal of important information from the game. Essential information from a game or platform should be presented to the player through multiple sensory channels including vision, audio, and haptic or touch.

In this unit, youâ€™ll be introduced to the principle of multiple sensory channels as it applies to:

- Text-based information
- Visual and Audio Cues
- Notifications and Status Indicators
- Directional Cues

## What are multiple sensory channels?

When gaming experiences provide important information to players, this information should be represented through multiple sensory channels. For example, any information presented to players visually should be accompanied by an audio or haptic representation of the same information. Similarly, information portrayed through audio should be accompanied by visual or haptic indicators.

The use of multiple sensory channels can help ensure that players who cannot perceive information presented visually are still aware of this information by consuming it through non-visual channels.  

## When should multiple sensory channels be used?

In general, multiple sensory channels should be used to represent information critical to successful interactions. Specific examples of these scenarios include the following areas:

### Text-based information

Games and platforms should provide players with an option to enable screen audio narration for all text-based elements within the UI. This includes menu, chat, notification, in-game tutorial, and objective log text. This narration provides players with visual disabilities access to important information represented through text.

### Visual and audio cues

Cues that are represented visually, like incoming enemy fire, the presence of nearby interactable objects, or nearby enemies, should also be represented through corresponding audio cues that have their own distinct sound. Similarly, cues that are conveyed through audio channels alone should have corresponding visual cues.

The following video capture from the game Grounded contains both visual and audio cues that inform the player that they are under attack. Visual cues like the red attack halos and health meter actively depleting are accompanied by corresponding audio cues like the player grunting when hit and the low health beep pattern to convey the same information through two different sensory channels.

> [!VIDEO https://www.microsoft.com/videoplayer/embed/RWOdS6]

### Directional cues

Navigating through a game is often a highly visual experience. Representing visual information like the spatial location of an exit door, interactable object, or nearby enemy through audio channels is important. Additionally, the representation of directional cues like waypoint markers and map locations are a common source of accessibility barriers.

Consider representing this visual information through additional audio cues like spatial audio pings or narrated directional cues. In the following video capture from the game Sea of Thieves, a player has the nautical narration setting enabled. As the player's character turns in space, moving the compass's direction, the current direction is narrated aloud through the audio channel.

> [!VIDEO https://www.microsoft.com/videoplayer/embed/RWObd2]
