To use a large language model (LLM), you can either run it locally or from a cloud provider, like Azure. The benefits of using a cloud hosted version are that the provider leaves you with guarantees that things will work, which means if you’re building a tech startup or adding a large language model to an existing product, you need that guarantee oftentimes for a customer to trust you. Also you data is yours, you don’t worry about the data leaking out. 

## Scenario: Trying out an LLM for my tech MVP

I have a tech startup within tourism, and I think I can use an LLM for a variety of tasks to run my business more efficiently but also to offer a better customer experience. Before I completely buy into using an LLM, I want to test it out to ensure it’s giving me useful responses. I imagine there should be some sort of testing playground. Another concern is that I want to make sure whatever I’m asking the LLM to do stays between me and my cloud provider.

## What will you learn?

In this module, you'll learn to:

- Provision an Azure OpenAI cloud resource.
- Create a deployment for a specific LLM model.
- Experiment with different prompts to see what type of results an LLM can give me in different situations.

## What is the main objective?

Provision and use a large language model deployment in Azure OpenAI studio.