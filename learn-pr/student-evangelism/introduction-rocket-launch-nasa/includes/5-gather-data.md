After you've clearly defined what you want to know, you can evaluate the data you have and the data that you might need to collect. From there, you can prepare your data in a way that supports the discovery you're interested in.

## Gather data

With constraints, scopes, and prioritization of data provided by SMEs in place, you can begin to gather useful data. This step presents its own challenges. Returning to the gardening example, you might grow 10 heads of lettuce under slightly different conditions, and then determine which conditions yield the best results.

For rocket launches, comparison experiments are not as easy to do. You can run simulations, but simulations are based on data, not on literal trial and error in exact conditions. It isn't ethical or economical to undertake a test launch under each unique circumstance to be able to determine with certainty the safest circumstances. Also, many conditions, like weather, can't be controlled. (But some of the data that's used in a simulation comes from failed rocket launches that were attempted under negative circumstances. Otherwise, how would you know the limitation sof certain conditions?) You also can use other information to determine constraints, like information that's gathered from aircraft or basic physics or calculations.

### Clean and manipulate data

At first impression, you might be suspicious to learn that one step in machine learning is to "manipulate" the data. In this case, however, manipulate doesn't mean that the data is modified to get a desirable outcome. It means that the data is made to be the most accurate representation of the truth.

For example, with your lettuce garden, you might run a study that focuses on soil moisture. You collect moisture readings every hour, so you can determine how moisture affects growth. One day, at 2:55 PM, the moisture sensor stops working. You notice it, and you fix the sensor before the scheduled 4:00 PM sensor reading. But, you lose the data that would have been collected at the schedule 3:00 PM sensor reading. It's reasonable to "manipulate" the data by replacing the missing value with an average of the 2:00 PM and 4:00 PM readings. If you don't notice the broken sensor until the next day, however, it might make more sense to "clean" your data by removing that day's readings from the analysis altogether, so incomplete data doesn't lead to an inaccurate result.

A large amount of data is needed to predict ideal conditions for a rocket launch. NASA is likely to have access to better data than what is publicly available. NASA has  access to the subject matter expertise of people who are involved in the nuances of rocket launches and weather. It also has access to all of its previous experiments and analyses. 

By contrast, in the machine learning model you'll train next, you'll rely mostly on accessible weather data like temperature, precipitation, and cloudiness. You'll focus on the days when a launch actually took place. The realistic result is that this project will be less accurate than NASA's predictions. Because you have only examples of successful launches, the machine learning model you train will be skewed toward good conditions. It won't be great at identifying bad conditions.