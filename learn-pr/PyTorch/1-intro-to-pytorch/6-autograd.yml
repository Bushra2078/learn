### YamlMime:ModuleUnit
uid: learn.PyTorch.intro-to-pytorch.autograd
title: Automatic Differentiation
metadata:
  title: Automatic Differentiation
  description: When training neural networks, the most frequently used algorithm is back propagation. In this algorithm, parameters (model weights) are adjusted according to the gradient of the loss function with respect to the given parameter.
  author: cassieview
  ms.author: cassieb
  ms.date: 04/14/2020
  ms.topic: interactive-tutorial
  ms.prod: azure
durationInMinutes: 10
content: |
  [!include[](includes/6-autograd.ipynb)]