A funny thing happens when engineers make mistakes and feel safe when giving details about it: they aren't only willing to be held accountable, but they're also enthusiastic about helping the rest of the company avoid the same error in the future.

They are, after all, the most expert in their error.

They ought to be heavily involved in coming up with remediation items.

So technically, engineers aren't at all "off the hook" with a blameless PostMortem process. They're very much on the hook for helping become safer and more resilient in the end. And lo and behold: most engineers I know find this idea of making things better for others a worthwhile exercise.

So, what do we do to enable a "Just Culture"?

 -  Encourage learning by having these blameless Postmortems on outages and accidents.
 -  The goal is to understand \*\*how \*\*an accident could have happened, to better equip ourselves from it happening in the future.
 -  Gather details from multiple perspectives on failures, and don't punish people for making mistakes.
 -  Instead of punishing engineers, we give them the requisite authority to improve safety by providing detailed accounts of their contributions to failures.
 -  Enable and encourage people who *make mistakes to educate* the rest of the organization on how not to make them in the future.
 -  Accept that there's always a discretionary space where humans can decide to make actions or not and that the judgment of those decisions lies in hindsight.
 -  Accept that the [Hindsight Bias](http://en.wikipedia.org/wiki/Hindsight) will continue to cloud our assessment of past events and work hard to eliminate it.
 -  Accept that the [Fundamental Attribution Error](http://en.wikipedia.org/wiki/Fundamental_attribution_error) is also difficult to escape, so we focus on the environment and circumstances people are working in when investigating accidents.
 -  Strive to make sure that the blunt end of the organization understands how work is getting done (as opposed to how they imagine it's getting done via Gantt charts and procedures) on the sharp end.
 -  The sharp end is relied upon to inform the organization of the line between appropriate and inappropriate behavior. It isn't something that the blunt end can come up with on its own.

Failure happens. To understand how failures occur, we first must understand our ***reactions*** to failure.

One option is to assume the single cause is incompetence and scream at engineers to make them "pay attention!" or "be more careful!"

Another option is to take a hard look at how the accident happened, treat the engineers involved with respect, and *learn* from the event.

For more information, see also:

 -  [Brian Harry's Blog - A good incident postmortem](https://blogs.msdn.microsoft.com/bharry/2018/03/02/a-good-incident-postmortem/)
