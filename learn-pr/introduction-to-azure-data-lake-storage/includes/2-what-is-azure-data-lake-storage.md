Let's begin with a quick look at Azure Data Lake Storage, including what it is and what are its core features. This overview should help you decide whether Azure Data Lake Storage is worth looking into as a solution for your company's big data storage requirements.

## What is a data lake?

A *data lake* is a centralized repository that enables you to store all your data—both structured and unstructured—in a single location. With a data lake, there's no need to conform your data to fit an existing structure. Instead, you can store your data in its raw or native format, usually as files or as binary large objects (blobs).

When evaluating whether a data lake is the right solution for your company, there are several elements to consider, as described in the following table.

| Element        | Description           |
| ------------- |-------------|
| Data speed      | A data lake must be able to ingest data at any speed: from the occasional file to large relational data imports to real-time data generated by web server logs or IoT devices. |
| Data scalability | Since a data lake might be required to store massive amounts of data that arrive in real time, the storage must be highly scalable to keep up with the demand. |
| Data availability | Once files, blobs, or relational data are stored in a data lake, they must be readily available through browsing, searching, and indexing of the data. |
| Data security      | Most data lakes store crucial data assets, including line-of-business data, company-developed apps, and productivity output. The data lake requires robust security to protect these assets.    |
| Data analytics | A data lake must store data in a way that enables business analysts, data scientists, and AI modelers to use their preferred tools to analyze the data in place to derive business intelligence, insights, trends, and forecasts.

A data lake enables your organization to quickly and easily store, access, and analyze a wide variety of data in a single location.

## Azure Data Lake Storage definition

Azure Data Lake Storage is a cloud-based, enterprise data lake solution engineered to store massive amounts of data in any format and to facilitate big data analytical workloads. Azure Data Lake Storage enables you to capture data of any size, type, and ingestion speed in a single location for easy access and analysis using a variety of frameworks.

> [!NOTE]
> The current implementation of Azure's data lake storage service is Azure Data Lake Storage Gen2. You might see references to the previous implementation, Azure Data Lake Storage Gen1, which is scheduled to be retired on February 29, 2024.

To help you understand Azure Data Lake Storage, you can examine the product from the following characteristics:

- Data storage
- Data access
- Data costs
- Data performance
- Data security
- Data redundancy
- Data scalability
- Data analysis

### Data Storage

Azure Data Lake Storage can store any type of data using the native format of that data. You don't need to define a schema or perform any type of transformation on the data before ingesting the data. Also, Azure Data Lake Storage doesn't perform any special handling of data based on the type of data it stores. With support for any data format and unlimited data sizes, Azure Data Lake Storage can work with structured, semi-structured, and unstructured data.

### Data Access

Azure Data Lake Storage is primarily designed to work with Hadoop and all frameworks that use the Hadoop Distributed File System (HDFS) as their data access layer. Hadoop distributions include the Azure Blob File System (ABFS) driver, which enables many applications and frameworks to access Azure Blob Storage data directly.

A key technology that enables Azure Data Lake Storage to provide high-performance data access at object storage scale and prices is the *hierarchical namespace*. A hierarchical namespace enables you to organize all the objects and files within your Azure Data Lake Storage account into a hierarchy of directories and nested subdirectories. In other words, your Azure Data Lake Storage data is organized in much the same way that files are organized on your computer.

### Data Costs

Azure Data Lake Storage is priced at Azure Blob Storage levels and builds on the powerful Azure Blob Storage capabilities like Automated Lifecycle Policy Management and Object Level tiering to manage big data storage costs. By using a hierarchical namespace, an Azure Data Lake Storage account provides the scalability and cost-effectiveness of object storage.

### Data Performance

The hierarchical namespace supported by Azure Data Lake Storage allows for efficient access and navigation. This architecture means that data processing requires fewer computational resources, which reduces both the time and cost of accessing data.

Azure Data Lake Storage supports high-throughput for input/output intensive analytics and data movement. In Azure Data Lake Storage, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance. Azure Data Lake Storage achieves throughput maximization by performing as many reads and writes in parallel as possible.

### Data Security

The Azure Data Lake Storage access control model supports both Azure role-based access control (Azure RBAC) and Portable Operating System Interface (POSIX) access control lists (ACLs). There are also a few extra security settings specific to Azure Data Lake Storage. You can set permissions either at the directory level or at the file level. All stored data is encrypted at rest using either Microsoft-managed or customer-managed encryption keys.

You can configure security settings a number of ways, including the following app and frameworks:

- Azure Storage Explorer
- Azure command-line interface
- Java
- JavaScript (Node.js)
- .NET
- PowerShell
- Python
- REST API

### Data Redundancy

Azure Data Lake Storage takes advantage of the Azure Blob replication models that provide data redundancy in a single data center with locally redundant storage (LRS), or to a secondary region by using the Geo-redundant storage (GRS) option. This feature ensures that your data is always available and protected if catastrophe strikes.

### Data Scalability

Azure Data Lake Storage offers unlimited storage and can store a variety of data types for analytics. It doesn't impose any limits on account sizes, file sizes, or the amount of data that can be stored in the data lake. Individual blobs and files can have sizes that range from a few kilobytes to a few petabytes. All of this means that Azure Data Lake Storage can easily and quickly scale up to meet the most demanding workloads, then just as easily scale back down when demand drops.

### Data Analysis

Via ABFS, data analysis frameworks that use HDFS as their data access layer—such as the Apache Spark analytics engine and the Presto SQL query engine—have direct access to Azure Data Lake Storage data.

In Azure, Data Lake Storage integrates with the following frameworks for analysis:

- Azure Data Explorer
- Azure HDInsight
- Azure Machine Learning
- Azure Stream Analytics
- Azure Synapse Analytics
- Power BI

Azure Data Lake Storage is also integrated into a massive and mature analytics ecosystem associated with Azure Blob Storage.

## How to prevent data silos

Data silos occur when different data sources are stored in separate locations, each of which can only be accessed by a specific application or framework. For example, a business analyst or data scientist who wants to analyze both sales data and web server logs must perform the following general steps:

1. Access one set of data.
1. Query the data.
1. Download the query results.
1. Repeat steps 1 through 3 for each set of data.
1. Process the downloaded data in a way that makes it possible to analyze the two data sets together.
1. Analyze the processed data.

That's a time-consuming, convoluted, and complex process. However, if all the required data is stored in Azure Data Lake Storage, the business analyst or data scientist can use their tool of choice—such as Power BI or Azure HDInsight—to work directly with all the data they need. Azure Data Lake Storage leaves it up to the individual analytic framework to interpret the data and define a schema at the time of the analysis.