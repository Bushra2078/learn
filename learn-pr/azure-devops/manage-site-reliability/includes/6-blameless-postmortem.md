
The Tailspin team is meeting to talk about how they'll handle the pressures of making the live production site a part of the pipeline.

**Mara**: DevOps, and I'm sure this comes as no surprise to any of us, advocates blameless postmortems. We just try to figure out what happened and how we can improve. 

**Andy**: Can you explain more?

## A Blameless Postmortem

Organizations that practice DevOps want to view mistakes, and errors with a goal of *learning*. Having blameless postmortems on outages and accidents are part of that goal.

Having a *Just Culture* means that you’re making an effort to balance safety and accountability. It means that by investigating mistakes in a way that focuses on the situational aspects of a failure and on the decision-making process of individuals close to the failure, an organization can come out safer than it would if it had simply punished the people involved.

A *blameless* post-mortem means that engineers whose actions have contributed to an accident can give a detailed account of:

- What actions they took at what time
- What effects they observed
- Expectations they had
- Assumptions they made
- Their understanding of timeline of events as they occurred

It's important that they can give this detailed account **without fear of punishment or retribution**.

An engineer who thinks they’re going to be reprimanded has no incentive to give a realistic, accurate account of the problem. Not understanding how an accident occurred all but guarantees that it *will* happen again, if not with the original engineer than with someone else.

> "We must strive to understand that accidents don’t happen because people gamble and lose.
Accidents happen because the person believes that:
…what is about to happen is not possible,
…or what is about to happen has no connection to what they are doing,
…or that the possibility of getting the intended outcome is well worth whatever risk there is."
>
>&mdash; <cite>Erik Hollnagel</cite>

## Allow engineers to own their own stories

A funny thing happens when engineers make mistakes and feel safe when giving details about it: they're not only willing to be held accountable, they're also enthusiastic in helping the rest of the company avoid the same error in the future. They are, after all, the ones with the most expertise when it comes to the error. They ought to be heavily involved in coming up with the remediation.

### What do we do to enable a "Just Culture"?

- Encourage learning by having blameless postmortems on outages and accidents.
- The goal is to understand *how* an accident could have happened in order to better equip ourselves from it happening in the future.
- Gather details from multiple perspectives on failures, and don’t punish people for making mistakes.
- Instead of punishing engineers, give them the requisite authority to improve safety by allowing them to give detailed accounts of their contributions to failures.
- Enable and encourage people who do make mistakes to be the experts on educating the rest of the organization on how not to make them in the future.
- Accept that there is always a discretionary space where humans can decide to  act or not, and that the assessment of those decisions lies in hindsight.
- Accept that the [Hindsight Bias](https://en.wikipedia.org/wiki/Hindsight_bias?azure-portal=true) will continue to cloud our assessment of past events, so work hard to eliminate it.
- Accept that the [Fundamental Attribution Error](https://en.wikipedia.org/wiki/Fundamental_attribution_error?azure-portal=true) is also difficult to escape, so focus on the environment and circumstances people are working in when investigating accidents.
- Strive to make sure that the blunt end of the organization understands how work is actually getting done (as opposed to how they imagine it’s getting done, via Gantt charts and procedures) on the sharp end.
- The sharp end must inform the organization where the line is between appropriate and inappropriate behavior. This isn’t something that the blunt end can come up with on its own.

Failure happens. In order to understand how failures happen, we first have to understand our reactions to failure.

## The end of the meeting

**Amita**: I think we can do this. We're a good team and we trust each other. Also, I plan on bringing donuts to every postmortem.

**Tim**: That's the answer.
