Copied form ILT

## design practices to measure end-user satisfaction

"Measurement is the first step that leads to control and eventually to improvement. If you can’t measure something, you can’t understand it. If you can’t understand it, you can’t control it. If you can’t control it, you can’t improve it." ― H. James Harrington

’User experience’ encompasses all aspects of the end-user’s interaction with the company, its services, and its products. UI (user interface) is not UX (user experience). A car with all its looks, dashboard and steering wheel is the UI. Driving it is the UX. So the interface directly contributes to the experience (beautiful car interior makes a better experience sitting in one), but is not the experience itself.

The only real measure of software quality that’s worth its salt is end-user satisfaction. Forget about what applications have been designed to do; forget about developer and service provider promises that don’t include an end-user analytical strategy. Cut to the chase and look at what’s actually happening; Measuring customer satisfaction doesn't have to be complicated or expensive. In fact, it's fairly simple to incorporate customer satisfaction measurement into your current customer success strategy. No matter how you cut it, measuring customer satisfaction comes down to gathering customer feedback via surveys. To accurately gauge customer sentiment, we'll simply need to ask them how their experience was.

Of course, there are multiple ways you can execute said survey, from the survey design to timing, sample, and even how you analyze the data. Let's briefly cover the five steps to easily measuring customer satisfaction.

1. Outline your goals, and make a plan When embarking on any sort of campaign, it's helpful to take a step back and ask, "Why are we doing this?" In business, one must weigh the value of additional information (i.e. the customer satisfaction data) in relation to the cost of collecting it (i.e. the survey process). To be honest, if you won't change anything after collecting your customer satisfaction data, you're better off not collecting it. It's going to take time and effort, so you need to put it to use.

Depending on your business or organizational capabilities, there is a lot you can do with the information. One use is simply to wake you up to the reality of any business: A portion of your customers is going to have an unsatisfactory experience. Every business faces this problem.

When you wake up to that fact, you can choose from many routes to correction. You can:

Improve key UX bottlenecks that contribute to poor customer experience.
Expedite customer support interactions with the most frustrated customers.
Operationalize proactive support like a knowledge base and customer education.
Test different live chat scripts and support strategies.
The specific solution isn't necessarily the important part here. The important part is stepping back and saying, "If we see that a segment of our customers is unsatisfied, what will we do about it?"

2. Create a customer satisfaction survey. What types of metrics measure customer satisfaction? You can choose among a few different options for customer satisfaction surveys. There's no unanimous agreement on which one is best. A few popular methods are:

Customer Satisfaction Score (CSAT)
Customer Effort Score (CES)
Net Promoter Score® (NPS)
These are all "one-question" methods that vastly simplify the process of collecting customer insights.

While you may not think the survey methodology matters much, how you ask the question does seem to measure slightly different things.

For instance, a 2010 study found twenty percent of "satisfied" customers said they intended to leave the company in question; 28% of the "dissatisfied" customers intended to stay. So "satisfied" doesn't necessarily equate to "loyal."

Customer Satisfaction Score (CSAT) is the most commonly used satisfaction method. You just ask your customers to rate their satisfaction on a linear scale. Your survey scale can be 1 – 3, 1 – 5, or 1 – 10, and there is no universal agreement on which scale is best to use. CSAT is a metric used to immediately evaluate a customer's specific experience. "CSAT is a transactional metric that is based on what's happening now to a user's satisfaction with a product or service."
Customer Effort Score (CES) is very similar, but instead of asking how satisfied the customer was, you ask them to gauge the ease of their experience. You're still measuring satisfaction, but in this way, you're gauging effort (the assumption being that the easier it is to complete a task, the better the experience). As it turns out, making an experience a low-effort one is one of the greatest ways to reduce frustration and disloyalty.
Net Promoter Score (NPS) asks the question, "How likely is it that you would recommend this company to a friend or colleague?" This attempts to measure customer satisfaction but also customer loyalty. In doing so, you can come up with an aggregate score, but you can also easily segment your responses into three categories: detractors, passives, and promoters. You calculate your Net Promoter Score by subtracting the percentage of Detractors from the percentage of Promoters.
You can, of course, use more than one methodology, as well (since they all measure something very slightly different). You can optionally combine multiple scores for a greater picture:

For example, a customer that has had 3 continuous negative CSAT scores over a period and is also a detractor on NPS would be an immediate at-risk customer, while a customer with positive CSAT and a promoter on NPS are potentially the best source of advocates & candidates to cross-sell/upsell since they already have seen the value in their interactions with the process & product.

In addition, I recommend always appending a qualitative open-ended question, regardless of the customer satisfaction survey you use. Without an open-ended question, you risk limiting your insight into "why" the dissatisfaction may be occurring. Qualitative user feedback can give you tons of ideas when it comes to implementing solutions.

3. Choose your survey's trigger and timing. This step is all about to whom you send the survey and when you send it. If you go back to your goals outline, this shouldn't be too hard to determine, at least strategically. People tend to forget this step, though, but it's of crucial importance and affects the quality and utility of your data. Tactically, you can trigger a survey pretty much anywhere at any time and to anyone nowadays, but strategically, it matters specifically when and where.

"Although there is no "one size fits all" approach to customer satisfaction surveys, there are 3 factors that every company should consider before surveying: What event or action took place before you asked for feedback (these can be time or action based events like completing your onboarding campaign), the time since your last survey to the customer, and is your team's ability to reply to feedback in a timely manner.

Good examples of event data that can be used to fire a survey are:

Time since signup
Key actions taken in your app
Complete user on-boarding
Surveying too often will result in low response rates, we recommend a customer satisfaction (NPS) survey seven days after signup, 30 days after the first survey and every 90 days during the customer lifecycle."
With all the options for triggering, though, let's start with some best practices:

The closer the survey is to the experience, the better.
People forget how they felt the longer you wait.
Who you survey changes what insights you get. If you survey website visitors about their satisfaction, the respondents are anonymous and may be a customer – or may not be. This will bring you different data than sending an email to recent customers will. Keep that in mind.
You should survey your customers more than once to see how things change longitudinally. Especially if you operate a SaaS company or a subscription service, regular NPS surveys can help you analyze trends both at the aggregate and individual level.
Survey people after a key moment of their customer journey.
If a respondent gives you a high score, think about adding a follow-up ask. For instance, Tinder asks you to rate their app in the app store if you give them a high score.
4. Analyze the survey data. Once you've collected your data, make sure it doesn't just sit there dormant and unused. You've got all this customer insight, and it's just waiting to be uncovered!

5. Make adjustments and repeat. Back to my first point: Now that you have these insights, what are you going to do about it? Ultimately, this is a personal decision that will reflect your own findings and capabilities. You may find that a whole segment is dissatisfied because of a particular experience. In that case, you may need to further investigate why that experience (or product) is causing dissatisfaction and run experiments to try to improve upon it. You may find that you have a small percentage of super fans.

Now that you can identify these people, perhaps you can work with your customer marketing and customer success teams to plan advocacy programs.

The possibilities are endless, but it all starts with accurately measuring customer satisfaction. But asking for scores is only a part of it – make sure you're creating conditions for customers to leave you high scores, too.

## In product feedback

It’s very likely that if you hang out here or on another web property for a little while, you’ll eventually be prompted to provide some feedback or sign up for something. Rate the app. Complete a one-question survey… Send a smile/frown, shake the device to provide feedback and various other interesting ways to engage users for feedback.

It is about meeting your customers where they are, done well, in-product feedback is a fantastic way to gather impactful, relevant information from people as they use your product. Done poorly, it’s a lethally effective way to drive people away or irritate them so much that they want to exact their revenge.

What kind of feedback can you expect?

Feedback from people who are already using your products, who have chosen to visit your website, who have otherwise opted-in to what you are selling…feedback from these people is worth its weight in pixels. Providing them a way to share feedback with you from within the context of your product makes this type of feedback especially valuable. It may be used to improve the usability of a particular feature or to recruit users who are already performing certain actions for deeper discussions. The main value is the immediacy of the feedback given the user’s context within your product. The feedback will tend to be more concrete, and users may be more likely to provide candid, quick responses.

Benefits

Context-Sensitive Feedback. Users will already be using your product, so they can provide feedback based on their actual usage or needs at the time. Priceless.
Always on. By implementing feedback mechanisms within the product itself, you’ve made it very easy for users to provide input, at any point, without sending a formal survey or otherwise cluttering an inbox in hopes of getting a hit.
High response rates. Since the feedback mechanism is built into your services, users are able to access it if and when they need it. That could mean reporting a problem, bug, enhancement or glitch or complementing the team on their choice of user experience.
Weaknesses

Too. Much. Feedback. There are a lot of channels which users can tap into to provide feedback. Sometimes, there are just too many to stay on top of them all. After all, it would be a shame to collect feedback from multiple channels and not have means to review it all…
Not enough detail. If you are posting micro-surveys within your site, the information you get back from respondents may not be sufficiently detailed to allow it to be actionable.
Always on. By implementing feedback mechanisms within the product itself, you’ve made it very easy for users to provide input, at any point, without sending a formal survey or otherwise cluttering an inbox in hopes of getting a hit. But, sometimes that feedback may be irrelevant given new decisions.
Limited future follow-up. Depending on the tools being used, you may not have enough contact information to follow-up directly with the person who submitted the feedback and delve deeper into their responses.
Tapping into In-Product feedback is helpful throughout the Product Development Lifecycle… In spite of it's weaknesses if done right, In-app feedback is an excellent way to validate existing or proposed functionality, and to solicit ideas for improvements to the status quo. Once the product is in production, use in-app tools to support users, allowing them to report issues, frustrations, improvements, and enhancements.

If you sell a software product, asking for feedback directly inside the app is a fantastic method for collecting product feedback.

It helps you narrow in on specific issues your customers are experiencing. However, it can also feel like paradox of choice since you can ask ANY question. Here are a few example questions that may be helpful to ask:

"What is {insert product feature} helping you accomplish?" "What issues, if any, are you having with {insert product feature}?" "What features do you think we’re missing today for {insert product feature}?"

There are hundreds of in-app questions you can ask. Here’s a preview of the pros and cons for in-app surveys.

Pros	Cons
Lots of flexibility - you can ask whichever question you see fit, whether you’re evaluating a new design, gauging how customers feel about a new feature launch, etc.	Difficult to comb through open-ended responses and extract insights.
Gives us access to the customer/user where they are in the app.	Low response rates.
Gives us context on what the user/customer is looking at in the app right before their response.	No ability to throttle NPS based on if a user has recently responded to feedback – need to be able to suppress certain users.
Allows us to respond in-app so I can keep all of my feedback in one place.	

## Feedback on product road-map

Feedback on product roadmap
Bookmark this page
The big thing that gets missed from feedback surveys is priority. Wouldn't it be great if there was a way to capture feedback and allow your customers to vote on what is most useful to them?

Effective communication on your product roadmap helps keep your customers engaged.. However, by giving your users the ability to request for features you can make them part of your product development inner loop. This is powerful, but at the same time you run the risk of driving your product into a direction where it becomes a niche solution only for a subset of the envisaged target market. By increasing the visibility on the requested features you can empower your full customer base to vote on features they would like to see most. This helps add a third dimension to product backlog and aids prioritisation.

It’s been shown that increased communication with customers promotes more engagement and feedback. By updating supporters of an idea as it moves through different product development stages - from discovery to planning to development and launch - your customers never feel like they’re in the dark.

The Azure DevOps team uses public projects to show it's feature plan for the next few months, you can check it out here.

Pros	Cons
Customers feel that they’re an active part of building your product roadmap. It provides a place to make customers feel their voice is heard	Likely biased towards your highest-intent customers. The people who aren't using your product are much more likely to withhold feedback or product suggestions.
Builds a sense of community and heightened loyalty when you can collaborate with the company on ideas.	Low volume unless customers are explicitly prompted to suggest an idea in the board.
Provides a channel through which you can make users feel appreciated for their contributions by letting them know that you’re taking action on their suggestions.	
Feature Request Board

A massive part of build a product is identifying new features customers desire. The easiest way to figure it out? Ask them! Creating a "feature request board" is a common tool for gauging product feedback from existing customers. Let's see how the integration between User Voice and Azure DevOps can help you create your own feature board for opening the feedback channels with your customers…

https://feedback.uservoice.com/knowledgebase/articles/363410-vsts-azure-devops-integration