In this module you will get to learn about how Azure Digital twins use event routes to send data to consumers outside the service.

It is also the fun part of this learning journey as you can finally start experiencing the ‘outcome’ of the hard work you invested in the previous modules in the form of insights, dashboards, visualizations, triggers, and so on.

:::image type="content" source="../media/adt-flow.png" alt-text="Diagram showing the flow of data from digital twins to unlocking insights" lightbox="../media/adt-flow.png":::

In an Azure Digital Twins solution, you can route event notifications to downstream services or connected compute resources. This is done by first setting up endpoints that can receive the events. You can then create event routes that specify which events generated by Azure Digital Twins are delivered to which endpoints.

There are many other services where you may want to ultimately direct your data, such as [Azure Storage](/azure/storage/common/storage-introduction), [Azure Maps](/azure/azure-maps/about-azure-maps), or [Time Series Insights](/azure/time-series-insights/overview-what-is-tsi). To send your data to services like these, first you need to attach the destination service to an endpoint.

## How do Event Routes work?

Endpoints are attached to Azure Digital Twins using management APIs or the Azure portal. Learn more about how to attach an endpoint to Azure Digital Twins in the documentation article [How-to: Manage endpoints and routes](/azure/digital-twins/how-to-manage-routes-apis-cli).

- Event routes use [Event Hub](/azure/event-hubs/event-hubs-about), [Event Grid](/azure/event-grid/overview), or [Service Bus](/azure/service-bus-messaging/service-bus-messaging-overview) to drive your desired data flows
- All events incoming to ADT or generated by ADT flow into a common event stream
- Developers can define routes to pick a subset of data items of the event stream and send them to endpoints

In this module, we will learn how to route events to Time Series Insights for querying and visualizing events received form Azure Digital Twins.

## What is Time Series Insights?

[Azure Time Series Insights](https://azure.microsoft.com/services/time-series-insights/) is an analytics platform to monitor, analyze, and visualize your industrial IoT data at scale. It also enables simple windowed compute in operational contexts to answer root-cause-analysis-type questions where operators, developers need more than last-known-values using real-time or near real-time insights from analytics to achieve operational optimization and excellence. For more information please visit:

- [Time Series Insight Documentation](/azure/time-series-insights/time-series-insights-overview)  
- Time Series Insights Learn Module: [Explore and analyze time-stamped data with Time Series Insights](/learn/modules/explore-analyze-time-series-insights/)

## Learning objectives

In this module you will:

- Build and simulate the Chocolate Factory Twin
- Create a route and filter to twin update notifications
- Create and configure an Azure function, and send telemetry to an event hub
- Create and connect a Time Series Insights instance
- Visualize and query your data in Time Series Insights

## Prerequisites

- Introductory knowledge of the purpose of Azure IoT
- Ability to use Node.js at the beginner level
- Experience using Visual Studio or Visual Studio Code at the beginner level
- It is recommended that you have introductory knowledge of Azure IoT, you can learn more by completing [Introduction to Azure IoT](/learn/paths/introduction-to-azure-iot/)
- A basic understanding of the Azure CLI. Following [Control Azure services with the CLI](/learn/modules/control-azure-services-with-cli/) module is recommended
- It is recommended if you have some experience working with Time Series Insights, you can learn more by completing the [Explore and analyze time-stamped data with Time Series Insights](/learn/modules/explore-analyze-time-series-insights/) module

This module is part of this learning path:

- Developing with Azure Digital Twins

## Introduction

In many cases data from ADT needs to be sent to downstream services for further analysis, integration, simulation, or processing. In this example, we will explore how to send the data to a Time Series Insights (TSI) instance to record time series data of manufacturing process events for bulk analytics.

Data egress is handled using Event Routes. An event route lets you send event data, such as telemetry events, life-cycle events, and property change events from twins to defined endpoints in your subscriptions, such as an Event Hub, an Event Grid, or a Service Bus.  

ADT will emit the following events (notifications and telemetry messages) and they will be routed to custom endpoints:

- Digital Twin Change Notification
- Digital Twin Lifecycle Notification
- Digital Twin Relationship Change Notification
- Digital Twin Telemetry Messages

:::image type="content" source="../media/event-flow.png" alt-text="Table showing the notification type, routing source name, and generated from descriptions" lightbox="../media/event-flow.png":::

The table shows the different notification types from [this doc article](/azure/digital-twins/how-to-interpret-event-data).

### Endpoints

To define an event route, developers first must define _endpoints_. An endpoint is a connection to a destination outside of ADT. Supported destinations are:

- EventGrid
- EventHub
- ServiceBus

:::image type="content" source="../media/adt-event-stream.png" alt-text="The diagram illustrates the flow of event data through a larger IoT solution with an Azure Digital Twins aspect" lightbox="../media/adt-event-stream.png":::

### Routes

Event routes are defined using data plane APIs. A route definition contains:

- The desired route ID  
- The desired endpoint ID
- A filter that defines which events are sent to the endpoint  

Some of the services you can tap into using routes:

- Storing Azure Digital Twins data in [Azure Data Lake](/azure/storage/blobs/data-lake-storage-introduction)
- Analyzing Azure Digital Twins data with [Azure Synapse Analytics](/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is), or other Microsoft data analytics tools
- Integrating larger workflows with Logic Apps
- Connecting Azure Digital Twins to Time Series Insights to track time series history of each twin
- Aligning a Time Series Model in Time Series Insights with a source in Azure Digital Twins
- Route events to compute services like Azure Functions for advanced simulation or data processing

## The scenario

Suppose you work at a Chocolate Manufacturing Factory as Technical Specialist to support The Chocolate Factory line operators. You are commissioned to launch a new near real-time dashboard to support operators monitor running operations for the Roasting, Grinding, and Molding processes to answer questions such as:

- _Find all-time windows when temperature during roasting is >150°F in the previous 24 hours and trace back events in ADT leading to that_
- _Calculate the average Grinding vibration in the last 2 minutes to ensure the process meets manufacturing quality standards_
- _Find all incidents with unusually higher than normal molding temperature in the previous five days_

Also, you may need to gather historical data that can be used for postmortem root-cause analysis when all operations fail, correct the problem, and set up a better notification system for these incidents.

:::image type="content" source="../media/chocolate-processes.png" alt-text="The main Chocolate Manufacturing Processes in scope: Roasting, Grinding, and Molding" lightbox="../media/chocolate-processes.png":::

## What you will do in this module

In the following units you'll go through these steps:

1. Build and simulate the Chocolate Factory Twin
1. Create a route and filter to twin update notifications using Azure Event Hub
1. Create and configure an Azure function, and send telemetry to an event hub
1. Create and connect a Time Series Insights instance
1. Visualize and query your data in Time Series Insights

### Solution Architecture

You will be attaching Time Series Insights to Azure Digital Twins using the pattern illustrated below:

### Prerequisites

This module and the following units assume you already have an Azure Digital Twins instance setup for the Chocolate Factory Production line and that the instance has been updated several times through connection to an IoT source of data, which streams sensors and actuators data connected to the factory assets to closely monitor the underlying processes and operations.

This pattern relies on the twin updates, rather than forwarding telemetry from an IoT device, which gives you the flexibility to change the underlying data source without needing to update your Time Series Insights logic.

:::image type="content" source="../media/architecture.png" alt-text="A diagram of the high-level architecture" lightbox="../media/architecture.png":::