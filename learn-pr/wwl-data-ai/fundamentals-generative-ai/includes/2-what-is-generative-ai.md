**Artificial Intelligence** imitates human behavior by relying on machines to learn and execute tasks without explicit directions on what to output.    

Generative AI applications take in natural language input, known as **prompts**, and return a response. 

Some examples of prompts include: 

|Common task | Sample prompt | Type of response |
|-|-|-|
|Generate and understand natural language text | "Give me three ideas for a healthy breakfast including peppers" | `Natural language` | 
|Generate and understand images | "Create an image of an elephant eating a burger" | `An image` |
|Generate and understand code | "Show me how to code a game of tic-tac-toe with Python" | `Code` | 

Consumers typically interact with generative AI that has been built into software applications through a chat interface. OpenAI, a company that partners closely with Microsoft, is best known as the company behind ChatGPT, an AI chatbot app based on a GPT LLM. Microsoft's partnership with OpenAI enables Azure OpenAI users to access the latest language model innovations.

Developers build generative AI applications like ChatGPT with large language models which are trained on massive volumes of text data. The sheer volume of training data and the way large language models are designed results in models that can generate human-like natural language responses or even original images based on what it has learned about the structure and semantic meaning of language. 

Consider these scenarios where a software application helps you by producing: 

- A bulleted list comparison between two types of cooking ingredients 
- A birthday card image based on your description
- Several suggested ways to start coding a solution to a programming problem 

We get responses that appear like the model understands our prompts because of language modeling. Understanding how generative AI's language modeling works can give you a greater ability to apply its capabilities with confidence. Next we will take a look at how language models have evolved.  
