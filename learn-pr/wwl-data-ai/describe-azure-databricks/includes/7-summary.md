In this module, you learned the basics about using Databricks workspace and Apache Spark notebooks. The notebooks allow you to interactively work with different types of data. You can use notebooks to process huge data files, query, read and write data from different sources, train machine learning models, and process live data streams.

Now that you have concluded this module, you should know:

1. How to Create a Cluster
2. How to Attach a Notebook to a Cluster
3. How to Execute Python, Scala, SQL or R code in a Notebook Cell
4. How to Detach a Notebook from a Cluster
5. How Azure Databricks fits into the Azure Ecosystem
6. How DBFS works to present Blob Storage as a Filesystem

## Clean up

If you plan on completing other Azure Databricks modules, don't delete your Azure Databricks instance yet. You can use the same environment for the other modules.

### Delete the Azure Databricks instance

1. Navigate to the Azure portal.
2. Navigate to the resource group that contains your Azure Databricks instance.
3. Select **Delete resource group**.
4. Type the name of the resource group in the confirmation text box.
5. Select **Delete**.
