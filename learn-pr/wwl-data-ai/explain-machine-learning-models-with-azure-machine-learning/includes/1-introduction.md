As machine learning becomes increasingly integral to decisions that affect health, safety, economic wellbeing, and other aspects of people's lives, it's important to be able to understand how models make predictions; and to be able to explain the rationale for machine learning based decisions.

Explaining models is difficult because of the range of machine learning algorithm types and the nature of how machine learning works, but model interpretability has become a key element of helping to make model predictions explainable.

## Learning objectives

In this module, you will learn how to:

- Interpret *global* and *local* feature importance.
- Use an explainer to interpret a model.
- Create model explanations in a training experiment.
- Visualize model explanations.
