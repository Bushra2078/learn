

AI is the defining technology of our time. It is already enabling faster and more profound progress in nearly every field of human endeavor and helping to address some of society’s most daunting challenges. For example, generative AI can help people with visual disabilities understand images by providing automatically alternative text for images. It can also help farmers produce enough food for our growing global population.

At Microsoft, we believe that the computational intelligence of AI should be used to amplify the innate creativity and ingenuity of humans. Our vision for AI is to empower every developer to innovate, empower organizations to transform industries, and empower people to transform society.

## Societal implications of AI

As with all great technological innovations in the past, the use of AI technology will have broad impacts on society, raising complex and challenging questions about the future we want to see. AI will have implications on decision-making across industries, data security and privacy, and the skills people need to succeed in the workplace. As we look to this future, we must ask ourselves: How do we design, build, and use AI systems that create a positive impact on individuals and society? How can we best prepare workers for the impact of AI? How can we attain the benefits of AI while respecting privacy?

## The importance of a responsible approach to AI

It’s important to recognize that as new intelligent technology emerges and proliferates throughout society, with its benefits will come unintended and unforeseen consequences, some with significant ethical ramifications and the potential to cause serious harm. While organizations can’t predict the future just yet, it’s our responsibility to make a concerted effort to anticipate and mitigate the unintended consequences of the technology we release into the world through deliberate planning and continual oversight.

### Threats

Each breakthrough in AI technologies brings a new reminder of this responsibility. In 2016, we released a chatbot on Twitter called Tay. We taught Tay to learn unsupervised from interactions with Twitter users, so she could better replicate human communication and personality traits. However, within 24 hours users realized that she could learn and began to feed her bigoted rhetoric, turning her from a polite bot into a vehicle for hate speech. This experience taught us that while technology may not be unethical on its own, people do not always have good intentions and we must consider the human element when designing AI systems.

We learned to prepare for new types of attacks that influence learning datasets, especially for AI systems that have automatic learning capabilities. To help ensure a similar experience does not happen again, we developed technology such as advanced content filters and introduced supervisors for AI systems with automatic learning capabilities. Current generative AI models, such as those provided in Azure Cognitive Services or Bing Chat, are built upon these insights.

More recently, generative AI is posing novel threats. This technology can create or edit videos, images, or audio files so credibly that they look real. This functionality can be useful in boosting the performance of art or marketing departments. However, it can also become a powerful tool for disinformation. For example, an AI-manipulated video of a politician could be used to manipulate public opinion in an election. This kind of deepfake-related threats may be one of the biggest current AI challenges. To solve this, Microsoft is teaming with other technology and news stakeholders to develop technical standards that certify media authenticity. Besides, there are efforts in raising awareness and creating simple guidelines for users to detect deepfakes.

### Biased outcomes

Another unintended consequence that organizations should keep in mind is that AI may reinforce societal or other biases without deliberate planning and design.

For example, Microsoft partnered with a large financial lending institution to develop a risk scoring system for loan approvals. When testing the system before deployment, we realized that it only approved loans for male borrowers. Since the system was trained on past customer’s data, it reproduced the historical sexist bias of loan officers. Validating the system before deployment allowed us to identify and address the issue before the system was operative.

It’s important for developers to understand how bias can be introduced into either training data or machine learning models. This problem can be particularly pervasive in premade models because the user may not be handling the training data themselves. At Microsoft, our researchers are exploring tools and techniques for detecting and reducing bias within AI systems. Prebuilt models are validated thoroughly, but nonetheless should be used wisely and their results should be always audited before taking action.

### Sensitive use cases

Another illustration of our responsibility to mitigate unintended consequences is with sensitive technologies like facial recognition. Recently, there has been a growing demand for facial recognition technology, especially from law enforcement organizations that see the potential of the technology for use cases like finding missing children. However, we recognize that these technologies could potentially be used by a government to put fundamental freedoms at risk by, for example, enabling continuous surveillance of specific individuals. We believe society has a responsibility to set appropriate boundaries for the use of these technologies, which includes ensuring governmental use of facial recognition technology remains subject to the rule of law.

While we believe that new laws and regulations must be written, we also recognize that they aren't a substitute for the responsibility that needs to be exercised by businesses, governments, NGOs, and academic researchers engaging with AI. This is why Microsoft assesses and develops principles to govern our work with facial recognition technologies. We anticipate these principles will evolve over time as we continue to learn and partner with customers, other tech companies, academics, civil society, and others on this issue.

There are technical and ethical challenges ahead of us. Responsible AI is the approach to solve them. Microsoft uses responsible AI practices to detect, prevent, and mitigate these issues, but any AI-related project should consider them as well. Microsoft has developed six guiding principles for responsible AI that will be helpful if you're working with AI.

Next, let’s see how Microsoft’s six guiding principles for responsible AI can be applied within other organizations.
