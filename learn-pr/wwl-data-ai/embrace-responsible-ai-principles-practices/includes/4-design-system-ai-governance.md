

Each organization will have their own guiding principles, but ultimately these principles need to be part of a larger responsible AI strategy to be effective. This strategy should encompass how your organization brings these principles to life both within your organization and beyond.

## Establishing an AI governance system

To provide oversight and guidance within your organization, we recommend establishing a governance system that is tailored to your organization’s unique characteristics, culture, guiding principles, and level of engagement with AI. The tasks of the board should include designing responsible AI policies and measures; attending they're being followed, and ensuring compliance.

To help your organization get started, we have provided an overview of three common governance approaches below: hiring a Chief Ethics Officer, establishing an ethics office, and forming an ethics committee. The first approach is centralized, and the others are decentralized. All of them have their benefits, but we recommend combining them in a hybrid mode. Besides, for any type of governance system to be successful, it must report to the board of directors and have the financial and human resources, authority, and processes to affect real change throughout the organization.

### Chief Ethics Officer

Often organizations choose to consolidate their ethics initiatives appointing a Chief Ethics Officer. This option has the advantage of centralized decision-making, so it enables organizations to quickly develop policies around ethics while ensuring there is accountability for each decision. Hiring this public-facing role can also be an effective way to showcase a company’s commitment to engage with AI and other technology in a responsible and trustworthy manner.

However, a Chief Ethics Officer alone may struggle to implement measures across an organization without the support of an ethics office. This drawback leads us to the next option.

### Ethics office

The second governance approach focuses on empowering employees across the organization. It involves forming a dedicated ethics team from different levels of the organization that is solely focused on ensuring the ethical principles are being followed by all employees. The ethics office can be independent or part of a broader risk, compliance, or legal team. If it's independent, it can be established without a leading role, but companies often choose a Chief Ethics Officer to head the office.

The key advantage of ethics offices is their ability to implement the policies at scale since they have dedicated team members working at all levels of the company. Ethics offices also prove adept at building a culture of integrity within an organization.

### Ethics committee

The last approach brings together a diverse array of outside experts and senior leaders from within the organization to address AI ethics. Ethics committees may even incorporate user groups, ethicists, or psychologists. Generally, they don't have members dedicated solely to ethics.

This form of governance provides an organization with perspectives from people with a wide range of diverse backgrounds and expertise, unbiased opinions from external members, and buy-in from senior leaders across the company.

## Governing AI deployment and development

No matter which governance approach you choose, there are some good practices it should promote:

* **Make resources available:** Employees will need guidance to learn responsible AI principles and incorporate them into their work. A handbook, a manual, or a training session can fulfill that task. 

* **Create a centralized AI inventory:** Having a list of all the AI models and systems operating in your organization is key to prioritize efforts and optimize resources. Besides, it's also helpful to make audits and compliance tests easier.

* **Develop tools:** Checking compliance in every AI system in your organization can be draining. Consider building tools to automate this task: such tools would monitor and validate systems and raise a flag if anything shifts outside of performance metrics.

More specific processes and polices will depend on whether your company is using third-party systems or developing AI in-house. Based on this factor, we have provided recommendations to help your company govern your AI engagements.

### Third-party AI systems

If your organization plans on leveraging out-of-the-box third-party AI solutions, we recommend learning about the third party’s commitment to responsible AI design to ensure it aligns with your own principles.

For custom AI solutions, include your principles or standards in your request for proposal. Before deploying any third-party AI solution, create guidelines on how to safely operate and monitor the system. Train employees on these guidelines and ensure they're being followed. Finally, your governance system should ensure the AI system has been rigorously tested.

### First-party AI systems

If your organization also plans to develop AI solutions or integrate AI into your existing products and services, there are some tasks for each team role.

Your **ethical governance system** should:
* Review or provide advice before the release of any new AI system, especially for sensitive use cases.

* Ensure employees from all levels of the company feel free to surface ethical concerns before you sell AI or AI-integrated products and services.

* Analyze the case and provide guidance to mitigate the risks if concerns arise while designing, developing, or selling the AI system.

* Create processes to monitor the AI systems you deploy or sell to detect and mitigate model drift and decay over time.

Your **developers** should:

* Be backed by detailed and thorough standard guidance that can help them design and develop AI solutions to reflect your organization’s ethical principles.

* Have guidelines and checklists for specific AI technologies, such as face recognition or generative AI.

### Engage with external stakeholders

As the use of AI becomes more common, we consider it a shared responsibility across the public and private sectors to engage with AI responsibly. Collaboration between enterprises, public organizations, governments, and non-profits is crucial to ensure best practices while maximizing AI’s potential to deliver broad benefits.

Organizations can contribute to these collective efforts in a number of ways. At Microsoft, we have focused on joining industry initiatives, influencing policy, addressing future labor and workplace needs, and considering how our technologies can be used to improve the lives of people around the world. For example, we have joined the **Partnership on AI (PAI)**, a group of researchers, non-profits, non-governmental organizations (NGOs), and companies dedicated to ensuring that AI is developed and utilized in a responsible manner.

Next, let’s discover how an AI governance system works in a real company. We'll take Microsoft as an example.
