### YamlMime:ModuleUnit
uid: learn.wwl.explore-azure-synapse-analytics.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 10/25/2021
  author: wwlpublish
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
azureSandbox: false
labModal: false
durationInMinutes: 2
content: |
  [!include[](includes/7-knowledge-check.md)]
quiz:
  title: "Check your knowledge"
  questions:
  - content: "Which component of an Azure Data Factory can be triggered to run data ingestion tasks?"
    choices:
    - content: "CSV File"
      isCorrect: false
      explanation: "That's incorrect. Even though a CSV file can be imported or exported, it cannot be run without an orchestration framework."
    - content: "Pipeline"
      isCorrect: true
      explanation: "That's correct. Pipelines can be triggered to run activities for ingesting data."
    - content: "Linked service"
      isCorrect: false
      explanation: "That's incorrect. A linked service specifies the connection parameters for connecting to an Azure service. It's not a task that you can run."
  - content: "When might you use PolyBase?"
    choices:
    - content: "To query data from external data sources from Azure Synapse Analytics"
      isCorrect: true
      explanation: "That's correct. This is the purpose of PolyBase"
    - content: "To ingest streaming data using Azure Databricks"
      isCorrect: false
      explanation: "That's incorrect. PolyBase is a data virtualization feature for SQL Server and doesn't extend support to Databricks."
    - content: "To orchestrate activities in Azure Data Factory"
      isCorrect: false
      explanation: "That's incorrect. You use Data Factory pipelines to orchestrate activities."
  - content: "Which of these services can be used to ingest data into Azure Synapse Analytics?"
    choices:
    - content: "Azure Data Factory"
      isCorrect: true
      explanation: "That's correct. Azure Data Factory can be used to ingest data into Azure Synapse Analytics from almost any source."
    - content: "Power BI"
      isCorrect: false
      explanation: "That's incorrect. Power BI is an analytics tool that can be used to report on the data within Azure Synapse Analytics."
    - content: "Azure Active Directory"
      isCorrect: false
      explanation: "That's incorrect. Azure Active Directory is an authentication mechanism, not a data ingestion framework."
  - content: "You have a large amount of data held in files in Azure Data Lake storage. You want to retrieve the data in these files and use it to populate tables held in Azure Synapse Analytics. Which processing option is most appropriate?"
    choices:
    - content: "Use Azure Synapse Link to connect to Azure Data Lake storage and download the data"
      isCorrect: false
      explanation: "That's incorrect. Azure Synapse Link enables you to connect to Azure Cosmos DB, not Data Lake storage."
    - content: "Synapse SQL pool"
      isCorrect: true
      explanation: "That's correct. You can use PolyBase from a SQL pool to connect to the files in Azure Data Lake as external tables, and then ingest the data."
    - content: "Synapse Spark pool"
      isCorrect: false
      explanation: "That's incorrect. You could use a Spark notebook to extract the data from Data Lake storage, but it is not the optimal solution for this scenario."
  - content: "Which of the components of Azure Synapse Analytics allows you to train AI models using AzureML?"
    choices:
    - content: "Synapse Studio"
      isCorrect: false
      explanation: "That's incorrect. It is true that you will likely use Synapse Studio as the interface, but it isn't the actual component that component that will do the training."
    - content: "Synapse Pipelines"
      isCorrect: false
      explanation: "That's incorrect. Synapse Pipelines is the orchestration component of Azure Synapse Analytics."
    - content: "Synapse Spark"
      isCorrect: true
      explanation: "That's correct. You would use a notebook to ingest and shape data, and then use SparkML and AzureML to train models with it."
  - content: "In Azure Databricks how do you change the language a cell uses?"
    choices:
    - content: "The first line in the cell is %language. For example, %scala."
      isCorrect: true
      explanation: "That's correct. Each cell can start with a language definition."
    - content: "Change the notebook language before writing the commands."
      isCorrect: false
      explanation: "That's incorrect. You can control the default language used in all the cells by setting the default. This doesn't allow you to change the language for each cell."
    - content: "Wrap the command in the cell with ##language##."
      isCorrect: false
      explanation: "That's incorrect. This isn't the correct syntax."