### YamlMime:ModuleUnit
uid: learn.wwl.work-dataframes-azure-databricks.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 05/15/2020
  author: wwlpublish
  ms.author: chtestao
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
azureSandbox: false
durationInMinutes: 5
quiz:
  questions:
  - content: "Which DataFrame method do you use to create a temporary view?"
    choices:
    - content: "createTempView()"
      isCorrect: false
      explanation: "This method name is incorrect."
    - content: "createTempViewDF()"
      isCorrect: false
      explanation: "This method name is incorrect."
    - content: "createOrReplaceTempView()"
      isCorrect: true
      explanation: "Correct. You use this method to create temporary views in DataFrames."
  - content: "How do you create a DataFrame object?"
    choices:
    - content: "Introduce a variable name and equate it to something like myDataFrameDF ="
      isCorrect: true
      explanation: "Correct. This approach is the correct way to create DataFrame objects."
    - content: "Use the createDataFrame() function"
      isCorrect: false
      explanation: "There's no such method for creating a DataFrame."
    - content: "Use the DF.create() syntax"
      isCorrect: false
      explanation: "This syntax is incorrect, and this approach isn't the right way to create DataFrame objects."
  - content: "How do you cache data into the memory of the local executor for instant access?"
    choices:
    - content: ".save().inMemory()"
      isCorrect: false
      explanation: "This syntax is incorrect."
    - content: ".inMemory().save()"
      isCorrect: false
      explanation: "This syntax is incorrect."
    - content: ".cache()"
      isCorrect: true
      explanation: "Correct. The cache() method is an alias for persist(). Calling this moves data into the memory of the local executor."
  - content: "What is the Python syntax for defining a DataFrame in Spark from an existing Parquet file in DBFS?"
    choices:
    - content: "IPGeocodeDF = parquet.read(\"dbfs:/mnt/training/ip-geocode.parquet\")"
      isCorrect: false
      explanation: "This syntax is incorrect."
    - content: "IPGeocodeDF = spark.read.parquet(\"dbfs:/mnt/training/ip-geocode.parquet\")"
      isCorrect: true
      explanation: "This syntax is correct."
    - content: "IPGeocodeDF = spark.parquet.read(\"dbfs:/mnt/training/ip-geocode.parquet\")"
      isCorrect: false
      explanation: "This syntax is incorrect."