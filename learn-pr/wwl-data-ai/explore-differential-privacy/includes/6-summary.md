In this module, you learned how:

- Differential privacy protects individual data values from being exposed in analyses.
- Differential privacy is configured using an *epsilon* value to determine the tradeoff between privacy and accuracy.
- The **SmartNoise** package provides an implementation of differential privacy that you can use to analyze data in Python.

To learn more about interpreting models, see [Differential Privacy](https://docs.microsoft.com/azure/machine-learning/concept-differential-privacy) in the Azure Machine Learning documentation.
