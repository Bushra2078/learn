### YamlMime:ModuleUnit
uid: learn.wwl.deep-learning-with-horovod-distributed-training.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 05/22/2020
  author: wwlpublish
  ms.author: chtestao
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
azureSandbox: false
durationInMinutes: 5
quiz:
  questions:
  - content: "Which of the following are utilized in the construction of a neural network?"
    choices:
    - content: "Learning rate."
      isCorrect: false
      explanation: "The learning rate is used at the time of training the neural network and it controls how much to adjust the networks weights given the loss at each iteration."
    - content: "Activation function."
      isCorrect: true
      explanation: "An activation function is used within the structure of a neural network."
    - content: "Loss function."
      isCorrect: false
      explanation: "The loss function is used by the optimizer at the time of training the neural network to compute the network loss at each iteration."
  - content: "What is the size, rank, and local rank when using Horovod to train a deep learning model on two servers, each with 2 GPUs?"
    choices:
    - content: "Size = 2, Rank: [0, 1, 2, 3], and Local Rank: [0, 1]"
      isCorrect: false
      explanation: "Size is total number of GPUs, i.e. 4. Rank is 0 to Size-1, i.e. [0, 1, 2, 3]. Local Rank is 0 to number of local GPUs - 1, i.e. [0, 1]."
    - content: "Size = 4, Rank: [0, 1, 2, 3], and Local Rank: [0, 1]"
      isCorrect: true
      explanation: "Size is total number of GPUs, i.e. 4. Rank is 0 to Size-1, i.e. [0, 1, 2, 3]. Local Rank is 0 to number of local GPUs - 1, i.e. [0, 1]."
    - content: "Size = 2, Rank: [1, 2, 3, 4], and Local Rank: [1, 2]"
      isCorrect: false
      explanation: "Size is total number of GPUs, i.e. 4. Rank is 0 to Size-1, i.e. [0, 1, 2, 3]. Local Rank is 0 to number of local GPUs - 1, i.e. [0, 1]."
  - content: "In the Horovod training script, what is the primary purpose of hvd.callbacks.BroadcastGlobalVariablesCallback(0) callback?"
    choices:
    - content: "To ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint."
      isCorrect: true
      explanation: "Correct. It is important to start all workers with the same initial state."
    - content: "To average metrics among workers at the end of every epoch."
      isCorrect: false
      explanation: "The correct callback to average metrics among workers at the end of every epoch is hvd.callbacks.MetricAverageCallback()."
    - content: "Reduce the learning rate if training plateaus."
      isCorrect: false
      explanation: "The correct callback to reduce the learning rate if training plateaus is ReduceLROnPlateau(patience=â€¦)."