While many applications work with text-based natural language input, it's also common to see applications that engage with users through speech; for example, digital assistants on smart phones, home automation devices, and in-car systems.

The Speech SDK is most commonly used with the Speech service, but it also offers integration with the Language Understanding service; enabling you to use a language model to predict intents from spoken input.

To use the Speech SDK with a Language Understanding model, enable the **Speech priming** publishing setting for your Language Understanding endpoint, and use the Speech SDK to write code that uses your Language Understanding prediction resource, as described in the next topic.
