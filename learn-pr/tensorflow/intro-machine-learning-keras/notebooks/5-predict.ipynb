{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming we achieved pretty good accuracy during the training and testing phases, we can now use the trained model for inference &mdash; in other words, to predict the classification of images that the network has never seen before.\n",
        "\n",
        "But before we move on, we'll load the code you've already seen in previous notebooks:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/kintro.py\n",
        "from kintro import *"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that in the previous notebook, after successfully training our network, we saved the model. Let's load it back into memory."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "  model = tf.keras.models.load_model('outputs/model')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbc584dbd90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction is easy &mdash; we simply call the model's `predict` method and pass one or more images. In our scenario, we'll predict the label for the following image:\n",
        "\n",
        "![Image of a shirt.](notebooks/images/3-predict-image.png)\n",
        "\n",
        "In the code below, we load the image, call `predict` to get its class index, and map that index to the class name.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/predict-image.png\n",
        "\n",
        "with Image.open('predict-image.png') as image:\n",
        "  X = np.asarray(image).reshape((-1, 28, 28)) / 255.0\n",
        "\n",
        "predicted_vector = model.predict(X)\n",
        "predicted_index = np.argmax(predicted_vector)\n",
        "predicted_name = labels_map[predicted_index]\n",
        "\n",
        "print(f'Predicted class: {predicted_name}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting:\n",
            "Actual: Bag, Predicted: Dress\n",
            "Actual: Sneaker, Predicted: Sneaker\n",
            "Actual: Ankle Boot, Predicted: Ankle Boot\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you can also get probabilities of the input image being of a certain class, in which case we need to normalize the output of our network using `softmax` to get probabilities. Here are the predictions for our image: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "probs = tf.nn.softmax(predicted_vector)\n",
        "for i,p in enumerate(probs):\n",
        "    print(f'{labels_map[i]} -> {p:.3f}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Shirt -> 0.102\n",
            "Trouser -> 0.002\n",
            "Pullover -> 0.001\n",
            "Dress -> 0.870\n",
            "Coat -> 0.001\n",
            "Sandal -> 0.000\n",
            "Shirt -> 0.023\n",
            "Sneaker -> 0.000\n",
            "Bag -> 0.001\n",
            "Ankle Boot -> 0.000\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to compute probabilities often, you can specify `activation='softmax'` for the final `Dense` layer of your network. In this case the network would give you probabilities as output, and you need to omit `use_logits=True` in the `SparseCategoricalCrossentropy` loss function. "
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernelspec": {
      "name": "conda-env-py37_tensorflow-py",
      "language": "python",
      "display_name": "py37_tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}