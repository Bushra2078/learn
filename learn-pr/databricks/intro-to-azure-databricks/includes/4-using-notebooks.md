
You can use Apache Spark notebooks to:

- Read and process huge files and data sets
- Query, explore, and visualize data sets
- Join disparate data sets found in data lakes
- Train and evaluate machine learning models
- Process live streams of data
- Perform analysis on large graph data sets and social networks

To learn more about using notebooks, clone the labs archive where sample notebooks are provided for you to understand how you can use notebooks for your day-to-day tasks.

## Clone the Databricks archive

1. In the Azure portal, navigate to your deployed Azure Databricks workspace and select **Launch Workspace**.
1. Within the Workspace, using the command bar on the left, select **Workspace**, **Users**, and select your username (the entry with the house icon).
1. In the blade that appears, select the downwards pointing chevron next to your name, and select **Import**.

    ![The menu option to import the archive](../media/import-archive.png)

1. In the Import Notebooks dialog, select the URL and paste in the following URL:
   ```
   https://github.com/MicrosoftDocs/mslearn-azure-databricks-notebooks-fundamentals/blob/master/DBC/01-notebook-fundamentals.dbc?raw=true
   ```
1. Select **Import**.
1. A folder called **01 Notebook Fundamentals** should appear. Select that folder.
1. The folder should contain a set of notebooks that you'll use in completing this lab.

## Complete the following notebooks

1. **01 Notebook Fundamentals** -  This notebook illustrates the fundamentals of a Databricks notebook.
1. **Why Apache Spark?** - This notebook allows you to practice some of the use cases for Databricks notebook.