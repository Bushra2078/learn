Azure Data Factory allows you to ingest data from different sources and build data pipelines. When you integrate Data Factory and Azure Databricks, you can create an end-to-end data workflow to ingest, prepare, transform, and load your data into any destination storage in the format and structure that you require.

**Additional Resources**

- [Run a Databricks notebook with the Databricks Notebook Activity in Azure Data Factory](https://docs.microsoft.com/azure/data-factory/transform-data-using-databricks-notebook)
- [Passing parameters between notebooks and Data Factory](https://docs.microsoft.com/azure/data-factory/transform-data-databricks-notebook#passing-parameters-between-notebooks-and-data-factory)
- [Branching and chaining activities in a Data Factory pipeline](https://docs.microsoft.com/azure/data-factory/tutorial-control-flow-portal)
- [Expressions and functions in Azure Data Factory](https://docs.microsoft.com/azure/data-factory/control-flow-expression-language-functions)

## Clean up

If you plan on completing other Azure Databricks modules, don't delete your Azure Databricks instance yet. You can use the same environment for the other modules.

### Delete the Azure Databricks instance

1. Navigate to the Azure portal.
1. Navigate to the resource group that contains your Azure Databricks instance.
1. Select **Delete resource group**.
1. Type the name of the resource group in the confirmation text box.
1. Select **Delete**.
