Suppose you work in the analytics department of a large airline company. You're part of a team that is working on analyzing the reasons for flight delays based on real-time data continuously being sent by flights around the world. Your job is to analyze the continuous flow of incoming data and stream it to the data lake storage. That data includes details such as airline, reason for delays, and departure time. You're using Azure Event Hubs to process your data.

## Learning objectives

In this module, you will:

- Use Spark Structured Streaming, Azure Event Hubs, and Databricks Delta to read from and write to streams.
- Process streaming data by using Azure Databricks.
