*Logging* refers to app-level diagnostic traces that developers include in the app code. The diagnostic information helps troubleshoot issues when the app doesn't behave as expected. Text-based event records are written to logs while the app is running. The logs include app traces and web server traces.

*Monitoring* refers to gathering platform and app metrics that are meant to track the app's health. Metrics are numerical values representing system status, such as CPU usage or requests received. Metrics are used to observe the system in near real-time or to analyze performance trends over time. The metrics are collected from different kinds of architectural levels. An example of such a level is the physical infrastructure to the app, including metrics from the:

* Node level
* Container
* Application
* Dependant services

## Implement logging in an ASP.NET Core microservice

Logging in a microservices-based solution can be challenging. There's a high volume of logs generated by many services, network calls, and dependant services working together to complete a business transaction. Other challenges in a microservices architecture include:

* Combining logs from multiple services into a single aggregated view.
* Parsing logs that come from multiple sources, which use their own logging schemas or have no particular schema. Logs may be generated by third-party components that you don't control.
* Understanding the end-to-end processing of a client request, where multiple services might be invoked to handle a single request.

Additional challenges when using a Kubernetes-based architecture include:

* Containers can move around and be rescheduled.
* Kubernetes has a networking abstraction that uses virtual IP addresses and port mappings.

In a microservices architecture, a solution is needed that can:

* Aggregate log traces from several microservices.
* Correlate the log traces.
* Carry additional contextual information, like the hosted infrastructure, to efficiently debug the app.

This unit explains how the *:::no-loc text="eShopOnContainers":::* app implements [Serilog](https://serilog.net) for structured logging and [Seq](https://datalust.co/seq) to centralize all log traces. In later units, you'll learn about using code instrumentation with Application Insights. Azure Monitor will be used for near real-time monitoring of the telemetry data.

### Structured logging

*Structured logging* is an approach in which the app writes logs in a structured format. An example of a structured format is JSON, while an unstructured log might be plain text. Unstructured text is difficult to query in a consistent manner. Microservices apps comprised of many services necessitate a way to filter the traces by a particular property, such as `TransactionId`.

.NET provides logging infrastructure in the `Microsoft.Extensions.Logging` assembly. The infrastructure provides APIs that work with various native and third-party logging providers. To implement structured logging in *:::no-loc text="eShopOnContainers":::*, [Serilog](https://github.com/serilog/serilog), an open-source third-party logging provider, is used.

Structured formats can be parsed to search and filter the relevant data based on their correlation. For example, consider the following logging statement that uses the Serilog library:

```csharp
_logger.LogInformation(
    "----- Begin transaction {TransactionId} for {CommandName} ({@Command})",
    transaction.TransactionId, commandName, command);
```

The usage of the `LogInformation` method is similar to that of the `string.Format` method. In the preceding parameters list for `LogInformation`:

1. The first string defines an event type or template property.
1. Properties for the log entry are in curly braces. For example, `{TransactionId}` defines a property that gets its value from the parameter `transaction.TransactionId`.
1. The `@` operator in front of `{@Command}` tells Serilog to serialize the object passed in, rather than convert it using `ToString`.

The resulting log entry is represented in the following JSON snippet:

```json
{
  "@t": "2020-10-12T14:07:35.5281920Z",
  "@mt": "----- Begin transaction {TransactionId} for {CommandName} ({@Command})",
  "@m": "----- Begin transaction 77fa1239-0abb-485f-bad2-f3ecd5e91128 for SetPaidOrderStatusCommand ({\n  \"OrderNumber\": 1,\n  \"_typeTag\": \"SetPaidOrderStatusCommand\"\n})",
  "@i": "79c44f1c",
  "TransactionId": "77fa1239-0abb-485f-bad2-f3ecd5e91128",
  "CommandName":"SetPaidOrderStatusCommand",
  "Command": {
    "OrderNumber" :1,
    "_typeTag": "SetPaidOrderStatusCommand"
  },
  "SourceContext": "Ordering.API.Application.Behaviors.TransactionBehaviour",
  "ApplicationContext": "Ordering.API",
  "TransactionContext":"77fa1239-0abb-485f-bad2-f3ecd5e91128",
  "IntegrationEventContext":"5f4b11b5-24be-40ca-9583-ed1c3d83ecb8-Ordering.API"
}
```

In the preceding JSON:

* The `@t` property is a timestamp.
* `@mt` is the message string.
* The remaining key-value pairs are the parameters.

Because the logs are being generated in a structured format, they can be visualized in a centralized logging system like Seq. Seq enables filtering based on the structured format, as shown:

:::image type="content" source="../media/3-logging-monitoring/structured-logging-visualization.png" alt-text="structured logging visualization" border="true" lightbox="../media/3-logging-monitoring/structured-logging-visualization.png":::

#### Logging contexts and correlation IDs

Logging context allows you to define a scope so you can trace and correlate a set of events. The trace can cross service contexts. Correlation IDs establish a link between two or more contexts. For example, in *:::no-loc text="eShopOnContainers":::*, each incoming request is assigned a unique ID. This unique ID is one dimension that can be used to correlate all the events related to that request. Serilog allows logging additional context values across all logging statements using [enrichment](https://github.com/serilog/serilog/wiki/Enrichment).

Some of the custom context properties used in *:::no-loc text="eShopOnContainers":::* include:

* `ApplicationContext` is defined on app startup and adds the `ApplicationContext` property to all events.
* `SourceContext` identifies the class's full name where the event is logged. It's often defined when creating or injecting the logger.
* `RequestId` is a specific context that covers all events while serving a request. The ASP.NET Core request pipeline defines it.
* `TransactionContext` covers the events from the beginning of the database transaction until it's committed.
* `IntegrationEventContext` identifies all events that occur while handling an integration event in an app.

This additional information is useful in understanding under what conditions the event was logged.

In Serilog, `Serilog.Context.LogContext` can be used to dynamically add and remove properties to a context. This feature must be added to the logger at configuration-time using `.FromLogContext()`:

```csharp
var log = new LoggerConfiguration()
    .Enrich.FromLogContext()
```

With that configuration, properties can be added to the context using `LogContext.PushProperty()`:

```csharp
public class OrderStartedIntegrationEventHandler : 
    IIntegrationEventHandler<OrderStartedIntegrationEvent>
{
    // Code omitted for brevity

    public OrderStartedIntegrationEventHandler(
        IBasketRepository repository,
        ILogger<OrderStartedIntegrationEventHandler> logger)
    {
        // Code omitted for brevity
    }

    public async Task Handle(OrderStartedIntegrationEvent @event)
    {
        using (LogContext.PushProperty("IntegrationEventContext", $"{@event.Id}-{Program.AppName}"))
        {
            _logger.LogInformation(
                "----- Handling integration event: {IntegrationEventId} at {AppName} - ({@IntegrationEvent})",
                @event.Id, Program.AppName, @event);

            await _repository.DeleteBasketAsync(@event.UserId.ToString());
        }
    }
}
```

The preceding code:

1. Defines a log property `IntegrationEventContext` as part of a `using` statement.
1. Sets the value of `IntegrationEventContext` to a string that includes `@event.ID` and `Program.AppName` values.
1. Applies that `IntegrationEventContext` property to all log events generated in the scope of the `using` statement. Any log methods invoked within the `DeleteBasketAsync` method are also considered in scope.

#### Serilog sinks & Seq

Serilog provides [sinks](https://github.com/serilog/serilog/wiki/Provided-Sinks) for writing log events to storage in various formats. In *:::no-loc text="eShopOnContainers":::*, Seq is configured as the centralized log monitoring system. Seq was selected for its free, single-user license, which can be used in production and can be run locally.

The following packages are added to every microservice to configure Serilog and Seq:

* `Serilog.AspNetCore`
* `Serilog.Enrichers.Environment`
* `Serilog.Settings.Configuration`
* `Serilog.Sinks.Console`
* `Serilog.Sinks.Seq`

Logger configuration is added in *:::no-loc text="Program.cs":::*, as shown here:

```csharp
private static Serilog.ILogger CreateSerilogLogger(IConfiguration configuration)
{
    var seqServerUrl = configuration["Serilog:SeqServerUrl"];

    return new LoggerConfiguration()
        .MinimumLevel.Verbose()
        .Enrich.WithProperty("ApplicationContext", AppName)
        .Enrich.FromLogContext()
        .WriteTo.Console()
        .WriteTo.Seq(string.IsNullOrWhiteSpace(seqServerUrl) ? "http://seq" : seqServerUrl)
        .ReadFrom.Configuration(configuration)
        .CreateLogger();
}
```

In the preceding code:

* `.Enrich.WithProperty("ApplicationContext", AppName)` defines the `ApplicationContext` for all traces in the app.
* `.Enrich.FromLogContext()` allows you to define a log context anywhere it's needed.
* `.ReadFrom.Configuration(configuration)` allows you to override the configuration from environment variables or values in *:::no-loc text="appsettings.json":::*. This ability to override configuration values is useful for containers.

The following JSON shows the default configuration in *:::no-loc text="appsettings.json":::* for an *:::no-loc text="eShopOnContainers":::* microservice:

```json
"Serilog": {
    "SeqServerUrl": null,
    "MinimumLevel": {
        "Default": "Information",
        "Override": {
            "Microsoft": "Warning",
            "Microsoft.eShopOnContainers": "Information",
            "System": "Warning"
        }
    }
},
```

Later in this module, you'll learn to configure the Serilog sink to Application Insights and monitor the telemetry data using Azure Monitor.

## Monitor the microservices app using Azure Monitor

Azure Monitor helps you understand how your cloud-native services are performing and proactively identifies issues affecting them. The following diagram provides a high-level view of Azure Monitor:

:::image type="content" source="../media/3-logging-monitoring/azure-monitor.png" alt-text="Azure Monitor visualization" border="true" lightbox="../media/3-logging-monitoring/azure-monitor.png":::

In the preceding diagram:

* The left side shows the sources of monitoring data that populate these data stores.
* The center shows the data stores for metrics and logs, which are the two fundamental types of data used by Azure Monitor.
* The right side shows the different functions that Azure Monitor performs with this collected data. These functions include analysis, alerting, and streaming to external systems.

[Azure Monitor for Containers](/azure/azure-monitor/insights/container-insights-overview) is a feature within Azure Monitor designed to observe the performance of container workloads deployed to AKS. It gives you performance visibility by collecting memory and processor metrics. Those metrics are collected from controllers, nodes, and containers available in Kubernetes through the Metrics API. Container logs are also collected. Metrics are written to the metrics store. Log data is written to the logs store associated with your Log Analytics workspace.

### Application performance management with Application Insights

Application Insights is an extensible Application Performance Management (APM) service. Apps are instrumented by installing an instrumentation NuGet package. This package monitors the app and sends telemetry data to the Application Insights service. The data is then sent to Azure Monitor. The Application Insights service also provides built-in correlation and dependency tracking.

### Collecting metrics with Prometheus

Generally, in a large microservices app, the telemetry data rate is high enough to trigger throttling. In such cases, you should consider exporting metrics to a time-series database such as Prometheus. [Prometheus](https://prometheus.io) is an open-source metric monitoring solution. Azure Monitor for Containers provides a seamless onboarding experience to collect Prometheus metrics.

To use Prometheus, you typically need a Prometheus server with a store. By integrating with Azure Monitor, a Prometheus server isn't required. Azure Monitor for Containers can scrape Prometheus metrics from instrumented apps without a separate Prometheus server.
