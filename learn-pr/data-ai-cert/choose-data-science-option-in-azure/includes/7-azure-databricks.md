Azure Databricks is a Spark based, secure, all-in-one, data science team collaboration platform, that includes a powerful notebooks interface, job scheduling, active directory integration, granular security control, and seamless Azure integration. It instantly gives the data science team everything they need to create machine learning pipelines end-to-end with Big Data.

## How it works

To use Azure Databricks, you provision an Azure Databricks Workspace using the portal. The workspace provides all the assets you need. From there, you can add users you want to have access to the workspace and refine the level of access from with Azure Databricks. The tools provided include a powerful notebook service that supports Big Data queries and visualizations. These notebooks can include all the languages supported by Spark, i.e. Scala, Java, SQL, Python, and R, all in the same notebook. Use the language you love but switch to another language if you need to. An advanced job scheduler allows you to schedule notebooks to run whenever you want and, if the cluster is not running, it will create it automatically and delete it at the end of the job. Assets such as notebooks can be shared and worked on collaboratively. Best of all, you don't need to worry about the complexities of configuring Spark clusters. The Azure Databricks GUI provides an easy to use interface to create and edit your cluster and even set automatic turn off of clusters after a period of nonuse. Clusters can be deleted without losing any data or notebooks so no need to keep clusters running. If you don't need them.

![Screenshot of Azure Databricks](../media/7-azure-databricks.png)

## Tools Integrated into Databricks

- Azure Databricks Notebook
- Job Scheduler
- Workspaces
- Granular Security Configuration
- Spark
- PySpark, SparkR
- CLI

## Example

### Step 1

Below is a picture of the Databricks landing page, and as you can see, under the 'Common Tasks' there is an option to start a new cluster. Begin with spinning up a cluster.

![Sceenshot of Databricks Landing Page](../media/7-databrick-landing-page.png)

### Step 2

Once the cluster is running, you can run a notebook on that cluster from the landing page.

### Step 3

Now, you have the notebook running on the cluster. You can run Python, R, Spark, PySpark, and other languages from here.

### Step 4

You can import the data from different Azure sources inside the notebook and begin the process of EDA, modeling, and evaluation.

## Summary

Azure Databricks is a Spark-based, secure, all-in-one, data science team collaboration platform, that includes a powerful notebooks interface, job scheduling, active directory integration, granular security control, and seamless Azure integration. It instantly gives the data science team everything they need to create machine learning pipelines end-to-end with Big Data.