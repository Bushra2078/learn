<!-- Original file: C:\Users\Mark\Desktop\CMU\v_5_3\content\_u05_distributed_programming_analytics_engines\_u05_m04_graphLab\x-oli-workbook_page\_u05_m04_5_computation_model.xml -->
As discussed on the previous page, GraphLab supports multiple engines which can execute the vertex functions either _synchronously_ or _asynchronously_. The three engines currently supported by GraphLab are the following: 


- Synchronous Engine
- Asynchronous Engine
- Asynchronous Engine - Serializable
##  Synchronous Engine
The synchronous engine executes the gather, apply and scatter (GAS) phases in order for each of the active vertices assigned to a machine. Once a machine completes updating all the vertices assigned to it for a particular iteration, it waits for the next iteration. Vertices that are activated in each iteration are scheduled for execution for the next iteration. In this execution mode, GraphLab actually executes the computation in Bulk-Synchronous (BSP) fashion, similar to systems such as Pregel. As a result, the computation performed by the synchronous engine is guaranteed to follow the _full consistency_ model as discussed in the previous page.

The Synchronous engine can perform extremely poorly when executing MLDM algorithms because a phase/stage/super-step during that execution cannot finish before the last task/vertex in that computation commits, and execution time of each phase/stage/super-step is determined by its slowest task/vertex (see the section Introduction to Distributed Programming for the Cloud ). 

##  Asynchronous Engine
Using the asynchronous engine, GraphLab executes active vertices as machines become available. Changes made to the vertex and edge data during the apply and scatter functions are immediately committed to the graph and made available for subsequent computation on neighboring vertices. The main benefit in using an asynchronous engine is in the elimination of waiting before the next iteration can proceed, which allows for increased parallelism and performance. The asynchronous engine executes vertex computations using the _vertex consistency_ model as discussed in the previous page.

Although asynchronous engines can result in empirical and algorithmic gains for a range of common MLDM applications, they pose a critical challenge. In particular, asynchronous execution presents design and debugging complexities and can yield nondeterministic results . For example, when statistical simulation is run asynchronously, there is a high potential for nondeterministic outcomes. If this condition is not carefully controlled, instability or even divergence can occur . In certain applications, the increased parallelism of asynchronous execution is offset by the increased number of iterations required to achieve convergence. 

##  Asynchronous-Serializable Engine
Graphlab provides a balanced tradeoff between the synchronous and asynchronous engines with the option of using the asynchronous-serializable engine. In this engine. GraphLab prevents adjacent verticesâ€™ GAS functions from running concurrently by using fine-grained, parallel locking protocol, known as the Chandy-Misra scheme. Using this scheme, a machine executing a vertex acquires locks on adjacent edges that are present on the machine (this is determined during the Greedy-Edge cut partitioning described earlier). The resulting execution is guaranteed to be _serializable_; i.e. there exists some serial ordering of execution whose results are equivalent to the results when executed using the asynchronous-seralizable engine. The asynchronous-serializable execution of a graph is equivalent to the _edge consistency_ model as discussed in the previous page.