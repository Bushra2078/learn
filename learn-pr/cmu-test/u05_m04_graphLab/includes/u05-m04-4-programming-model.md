<!-- Original file: C:\Users\Mark\Desktop\CMU-source\v_5_3\content\_u05_distributed_programming_analytics_engines\_u05_m04_graphLab\x-oli-workbook_page\_u05_m04_4_programming_model.xml -->

##  The GraphLab Programming Model

Recall from the data model of GraphLab, graphs are partitioned between multiple machines. During the execution of the GAS functions on each vertex, there exists potential for read-write and write-write conflicts among vertices that share scope. The GraphLab engine synchronizes shared data accesses and ensures consistent parallel execution. In particular, GraphLab supports different graph execution engines, each with different levels of consistency, allowing users to choose an engine appropriate for correctness and performance in their applications. The different notions of consistency offered by GraphLab through its various engines are: **full consistency**, **edge consistency**, and **vertex consistency**. As shown in Figure 5.49, under full consistency, the update function at each vertex (vertex 3) has an exclusive read-write access to its own vertex, adjacent edges, and adjacent vertices (its entire scope). While this arrangement guarantees strong consistency and full correctness, it limits parallelism and, consequently, performance. Vertices in many MLDM algorithms, however, really do not require exclusive read-write access to their entire scope. For instance, the PageRank algorithm requires only read access to neighboring edges and vertices. 

Thus, to increase parallelism and support a broader range of consistency settings that suit various MLDM applications, GraphLab includes notions of edge consistency and vertex consistency. Under edge consistency, the update function at a vertex has an exclusive read-write access to its vertex and adjacent edges, yet a read-only access to adjacent vertices. Clearly, this protocol relaxes consistency and enables a superior leverage of parallelism. Under vertex consistency, the update function at a vertex has exclusive write access only to its own vertex, thus allowing all update functions to run simultaneously. This capability provides the maximum possible parallelism but, in return, the most relaxed consistency. GraphLab users can choose an engine that balances performance with the required consistency model they find convenient for their applications.

![Figure 5.49: The full consistency, the edge consistency, and the vertex consistency models guaranteed by GraphLab. The full consistency model is the strongest, and the vertex consistency is the most relaxed one. As consistency is relaxed, parallelism is increased and vice versa.](../media/full_consistency.png)

_Figure 5.49: The full consistency, the edge consistency, and the vertex consistency models guaranteed by GraphLab. The full consistency model is the strongest, and the vertex consistency is the most relaxed one. As consistency is relaxed, parallelism is increased and vice versa._


As part of its shared-memory view, GraphLab stores ghosts, the adjacency information/data of each vertex (see the section ), in local memories. A vertex ghost ensures that the vertex's update function has direct memory access to all data within its scope. 

### References

1. _Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M. Hellerstein (2010). GraphLab: A New Parallel Framework for Machine Learning Conference on Uncertainty in Artificial Intelligence (UAI)_
2. _Low, Y., Gonzalez, J., Kyrola, A., Bickson, D., Guestrin, C., and Hellerstein, J. M. (2012). Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud PVLDB_
3. _J. Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin (October, 2012). PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs In Proc. of the 10th USENIX Conference on Operating Systems Design and Implementation_