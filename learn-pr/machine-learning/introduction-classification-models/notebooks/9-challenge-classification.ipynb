{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wine experts can identify wines from specific vineyards through smell and taste, but the factors that give different wines their individual characteristics are actually based on their chemical composition.\n",
        "\n",
        "In this challenge, you'll train a classification model to analyze the chemical and visual features of wine samples and classify them based on their cultivar (grape variety).\n",
        "\n",
        "> **Citation**: The data that we're using in this exercise was originally collected by Forina, M. et al. \n",
        "> \n",
        "> PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy. \n",
        "> \n",
        "> You can download it from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science).\n",
        "\n",
        "### Explore the data\n",
        "\n",
        "Let's hit the ground running by importing a CSV file of wine data, which consists of 12 numeric features and a classification label with the following classes:\n",
        "\n",
        "-   **0** (*variety A*)\n",
        "-   **1** (*variety B*)\n",
        "-   **2** (*variety C*)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the required packages into your current R session\n",
        "suppressPackageStartupMessages({\n",
        "  library(tidyverse)\n",
        "  library(tidymodels)\n",
        "  library(here)\n",
        "  library(janitor)\n",
        "})\n",
        "\n",
        "# Read the CSV file into a tibble\n",
        "wine_data <- read_csv(file = \"https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/challenges/data/wine.csv\", show_col_types = FALSE)\n",
        "\n",
        "# Print the first 10 rows of the data\n",
        "wine_data %>% \n",
        "  slice_head(n = 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Your challenge is to explore the data and train a classification model that achieves an overall *recall* metric of over 0.95 (95 percent).\n",
        "\n",
        "Let's kick off your adventure by reformatting the data to make it easier for a model to use it effectively.\n",
        "\n",
        "**Step 1**\n",
        "\n",
        "Starting with the `wine_data`, encode the `WineVariety` column to a categorical variable (factor) with levels set as: 0, 1, 2. \n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the janitor package for cleaning data\n",
        "library(janitor)\n",
        "\n",
        "# Clean data a bit\n",
        "wine_data <- wine_data %>%\n",
        "  # Encode WineVariety as category\n",
        "  mutate(....) %>% \n",
        "  # Clean column names\n",
        "  clean_names()\n",
        "\n",
        "\n",
        "# View data set\n",
        "wine_data %>% \n",
        "  glimpse()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 1.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of data exploration is to try to understand the *relationships* between its attributes. In particular, you want to understand any apparent correlation between the *features* and the *label* that your model will try to predict. One way to do this is to use data visualization.\n",
        "\n",
        "Now let's compare the feature distributions for each label value.\n",
        "\n",
        "**Step 2**\n",
        "\n",
        "Begin by restructuring the data such that you can easily plot your data as facets, subplots that display one subset of the data per each. You do this by using [`facet_wrap`](https://ggplot2.tidyverse.org/reference/facet_wrap.html).\n",
        "\n",
        "Use `pivot_longer` (to increase the number of rows and decrease the number of columns) such that all the existing column names except *wine_variety* now fall under a new column name called *features* and their corresponding values under a new column name *values*.\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "theme_set(theme_light())\n",
        "# Pivot data to a long format\n",
        "wine_data_long <- wine_data %>% \n",
        "    pivot_longer(....)\n",
        "\n",
        "\n",
        "# Make a box plot for each predictor feature\n",
        "wine_data_long %>% \n",
        "  ggplot(mapping = aes(x = wine_variety, y = values, fill = features)) +\n",
        "  geom_boxplot() + \n",
        "  facet_wrap(~ features, scales = \"free\", ncol = 5) +\n",
        "  scale_color_viridis_d(option = \"plasma\", end = .7) +\n",
        "  theme(legend.position = \"none\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 2.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What insights about the wine varieties have you derived from the distribution of the different features?\n",
        "\n",
        "### Split the data for training and validation\n",
        "\n",
        "Now, time to train some models. It's best practice to hold out some of your data for *testing* in order to get a better estimate of how your models will perform on new data by comparing the predicted labels with the already known labels in the test set.\n",
        "\n",
        "**Step 3**\n",
        "\n",
        "In this section:\n",
        "\n",
        "-   Make a split specification of `wine_data` such that *70%* goes to training and the rest goes to testing. Save this to a variable name `wine_split`\n",
        "\n",
        "-   Extract the training and testing sets from `wine_split` and save them in `wine_train` and `wine_test` variable names respectively.\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the Tidymodels packages\n",
        "library(tidymodels)\n",
        "\n",
        "\n",
        "# Split data into 70% for training and 30% for testing\n",
        "set.seed(2056)\n",
        "wine_split <- wine_data %>% \n",
        "  ....(prop = ....)\n",
        "\n",
        "# Extract the data in each split\n",
        "wine_train <- ....(wine_split)\n",
        "wine_test <- ....\n",
        "\n",
        "\n",
        "# Print the number of cases in each split\n",
        "cat(\"Training cases: \", nrow(wine_train), \"\\n\",\n",
        "    \"Test cases: \", nrow(wine_test), sep = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 3.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing with recipes\n",
        "\n",
        "Now that you have a set of training features and corresponding training label (`wine_variety`), you can fit a multiclass classification algorithm to the data to create a model.\n",
        "\n",
        "The function `parsnip::multinom_reg()` defines a model that uses linear predictors to predict multiclass data by using the multinomial distribution.\n",
        "\n",
        "**Step 4**\n",
        "\n",
        "In this section, do three things:\n",
        "\n",
        "-   Create a multinomial model specification, `mr_spec`, that uses `nnet` package as its engine and whose mode is set to `classification`. This model has one tuning parameter, `penalty`, which is the amount of regularization. The best way to estimate this value is to *tune* it but, for now, set it to an arbitrary value, say *1*.\n",
        "\n",
        "-   Create a recipe, `wine_recipe`, with `wine_variety` as the outcome and the rest as predictors, and a step that specifies that all the numeric predictors should be normalized.\n",
        "\n",
        "-   Bundle the model specification and recipe into a workflow, `mr_wflow`.\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Specify a multinomial regression via nnet\n",
        "mr_spec <- ....(\n",
        "  penalty = ....,\n",
        "  engine = ....,\n",
        "  .... = \"classification\"\n",
        ")\n",
        "\n",
        "\n",
        "# Create a recipe that specifies that predictors should be on the same scale\n",
        "wine_recipe <- recipe(...., data = wine_train) %>% \n",
        "  ....(all_numeric_predictors())\n",
        "\n",
        "# Bundle recipe and model specification into a workflow\n",
        "mr_wflow <- workflow(preprocessor = ...., spec = ....)\n",
        "\n",
        "# Print out workflow\n",
        "mr_wflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 4.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fantastic!\n",
        "\n",
        "After you've *specified* a workflow, you can *train* a model by using the [`fit()`](https://tidymodels.github.io/parsnip/reference/fit.html) function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Fit a workflow object\n",
        "mr_wflow_fit <- mr_wflow %>% \n",
        "  fit(data = wine_train)\n",
        "\n",
        "# Print wf object\n",
        "mr_wflow_fit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate model performance\n",
        "\n",
        "Good job! You now have a trained workflow. The workflow's printout shows the coefficients learned during training.\n",
        "\n",
        "With this workflow, you can use the model trained by the workflow to predict labels and their corresponding class probabilities for the test set.\n",
        "\n",
        "**Step 5**\n",
        "\n",
        "Obtain a tibble that contains the actual wine varieties of the test set, the hard class wine variety predictions, and their corresponding probability predictions.\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Obtain predictions on the test set\n",
        "results <- ....\n",
        "\n",
        "# Print the results\n",
        "results %>% \n",
        "  slice_head(n = 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 5.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome! It's time to evaluate how your model performs. Let's look at the confusion matrix for your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "results %>% \n",
        "  conf_mat(truth = wine_variety, estimate = .pred_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The confusion matrix shows the intersection of predicted and actual label values for each class. In simpler terms, the diagonal intersections from top-left to bottom-right indicate the number of correct predictions.\n",
        "\n",
        "When you're dealing with multiple classes, it's ordinarily more intuitive to visualize this matrix as a heat map, like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "results %>% \n",
        "  ....(wine_variety, .pred_class) %>% \n",
        "  autoplot(type = \"heatmap\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The darker squares in the confusion matrix plot indicate higher numbers of cases and, hopefully, you can see a diagonal line of darker squares indicating cases where the predicted and actual label are the same.\n",
        "\n",
        "The confusion matrix is helpful, because it gives rise to other metrics that can help you better evaluate the performance of a classification model. Let's go through some of them:\n",
        "\n",
        "* **Precision**: *TP/(TP + FP)*, the proportion of predicted positives that are actually positive.\n",
        "* **Recall**: *TP/(TP + FN)*, the proportion of positive results out of the number of samples that were actually positive.\n",
        "* **Accuracy**: *TP + TN/(TP + TN + FP + FN)*, the proportion of labels predicted accurately for a sample.\n",
        "\n",
        "**Step 6**\n",
        "\n",
        "Use the `yardstick` package to obtain the following metrics:\n",
        "\n",
        "-   Accuracy\n",
        "-   Precision\n",
        "-   Recall\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Statistical summaries for the confusion matrix\n",
        "accuracy = accuracy(data = results, truth = ...., estimate = .pred_class)\n",
        "\n",
        "\n",
        "precision = precision(....)\n",
        "\n",
        "recall = ....\n",
        "\n",
        "# Print metrics\n",
        "accuracy %>% \n",
        "  bind_rows(precision) %>% \n",
        "  bind_rows(recall)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 6.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What do you think of these metrics?\n",
        "\n",
        "Let's now evaluate the receiver operating characteristic (ROC) metrics. In the case of a multiclass classification model, a single ROC curve showing the true positive rate versus the false positive rate is not possible. However, you can use the rates for each class in a One-vs-Rest (OVR) comparison to create a ROC chart for each class, as shown here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Make an ROC curve\n",
        "results %>% \n",
        "  roc_curve(wine_variety, c(.pred_0, .pred_1, .pred_2)) %>% \n",
        "  ggplot(aes(x = 1 - specificity, y = sensitivity, color = .level)) +\n",
        "  geom_abline(lty = 2, color = \"gray80\", size = 0.9) +\n",
        "  geom_path(show.legend = T, alpha = 0.6, size = 1.2) +\n",
        "  coord_equal()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7**\n",
        "\n",
        "To quantify the ROC performance, calculate an aggregate area under the curve score, which is then averaged across all the OVR curves.\n",
        "\n",
        "Fill in the placeholder `....` with the right code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate ROC_AUC\n",
        "auc <- results %>% \n",
        "  roc_auc(....)\n",
        "\n",
        "auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        ". <- ottr::check(\"tests/Question 7.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, did your model do a great job of classifying the wine varieties?\n",
        "\n",
        "### Use the model with new data observation\n",
        "\n",
        "When you're happy with your model's predictive performance, save it, and then use it to predict classes for the following two new wine samples:\n",
        "\n",
        "- \\[13.72, 1.43, 2.5, 16.7, 108, 3.4, 3.67, 0.19, 2.04, 6.8, 0.89, 2.87, 1285\\]\n",
        "\n",
        "- \\[12.37, 0.94, 1.36, 10.6, 88, 1.98, 0.57, 0.28, 0.42, 1.95, 1.05, 1.82, 520\\]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(here)\n",
        "# Save trained workflow\n",
        "saveRDS(mr_wflow_fit, \"wine_mr_model.rds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now load it whenever you need it, and use it to predict labels for new data. This is often called *scoring* or *inferencing*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Create a tibble for the new wine samples\n",
        "new_wines <- c(13.72, 1.43, 2.5, 16.7, 108, 3.4, 3.67, 0.19, 2.04, 6.8, 0.89, 2.87, 1285) %>% \n",
        "  rbind(c(12.37, 0.94, 1.36, 10.6, 88, 1.98, 0.57, 0.28, 0.42, 1.95, 1.05, 1.82, 520)) %>% \n",
        "  as_tibble()\n",
        "names(new_wines) = names(wine_data)[1:13]\n",
        "\n",
        "new_wines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the model into the current R session\n",
        "loaded_model <- readRDS(\"wine_mr_model.rds\")\n",
        "\n",
        "# Make predictions\n",
        "predictions <- loaded_model %>% \n",
        "  augment(new_data = new_wines)\n",
        "\n",
        "predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it for now. Congratulations on finishing this challenge notebook! The adventure doesn't stop here. You could try tuning that hyperparameter, or try out a new model entirely.\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": "",
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.4.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
