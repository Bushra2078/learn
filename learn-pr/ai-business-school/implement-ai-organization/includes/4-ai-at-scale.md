## Multitasking AI models are the future of AI

A new approach to AI is creating a groundbreaking new class of machine learning models.

Traditionally, machine learning models have been trained for a specific task, like translating between languages, recognizing objects in an image or video, extracting key points from text, or making a prediction based on quantitative data. Most AI solutions are built using one or several of these purpose-built models.

But recently, researchers have been training AI models that can perform multiple tasks. These models are called “large” or “massive” because they have billions of “parameters,” or connections between nodes in the model’s neural network. To illustrate just how powerful these cutting-edge models are: models with only millions of parameters achieved human parity in object recognition, speech recognition, and translation. Multi-tasking AI models will jumpstart a whole new breed of AI applications that weren't possible before.

According to a 2018 OpenAI analysis,<sup>3</sup> from 2012 to 2018 the amount of compute used in the largest AI training runs grew more than 300,000 times with a 3.5-month doubling time. Just in the year 2020, the size of natural language generation (NLG) models has increased exponentially – from less than 20 billion parameters to 175 billion.

As you can imagine, training these large, multi-tasking models requires expertise, years of work, and massive amounts of training data. It also requires the most advanced supercomputing infrastructure and techniques for training the models across many pieces of hardware.

## Microsoft “AI at Scale” initiative

Through our AI at Scale initiative, we're providing organizations with access to large multi-tasking AI models and the supercomputing resources needed to create them, dramatically reducing the barriers and costs associated with accessing next-generation AI capabilities.

In collaboration with OpenAI, we’ve built a supercomputer designed specifically for training extremely large AI models. 

We’ve also developed our own family of large AI models, called the Microsoft Turing models. These include the world’s largest publicly available language model, the *Microsoft Turing model for natural language generation*, which has 17 billion parameters. This model has a deep understanding of grammar, context, and intended meaning that has helped it set new benchmarks in many different language-related tasks, such as summarization, contextual prediction, and question answering.

By making this breakthrough technology available to all, we hope to empower organizations, developers, and employees to unlock innovation that was previously impossible.

## Three ways to take advantage

### Create your own multi-tasking AI models with our supercomputer

If your organization is ready to create your own large AI models, you can harness the power of our supercomputer through Azure. With more than 285,000 CPU cores, 10,000 GPUs, and the latest high-bandwidth network, it ranks in the top five supercomputers in the world.

We’re also providing the tools you need to train large AI models on the supercomputer efficiently and cost-effectively. We have DeepSpeed, an open-source Pytorch library that provides techniques for training large models 10 times faster. We also have ONNX Runtime, an open-source engine that enables highly efficient model training. We’ll continue to create optimization techniques that push the boundaries of scaling and efficiency and offer them through our Azure Machine Learning platform.

### Innovate on top of the some of the most sophisticated models in the world

If you’re interested in using the Microsoft Turing models for your own AI solutions, we’ve made them open source for organizations and developers to access. Our language understanding and language generation models are available today, with others coming soon.

You can use the Turing models as they are or customize them for your own scenarios. After a model has been trained for general tasks, it can be fine-tuned for more specific tasks by training with additional data. For example, a company could take a pre-trained language model and teach it more specific vocabulary by training it with industry- and company-specific text. This same process is used to customize smaller models as well, but it’s even more beneficial for large models. We provide open-source guidance for customizing large models in the Azure Machine Learning platform.

With access to this world class technology, your technical teams will be able to fast-track the AI development cycle and deliver business value at an unprecedented pace and quality. 

### Bring transformational capabilities to everyone with Turing models built into Microsoft products

Finally, every organization can benefit from Turing models today, because they're baked into our products. We've used the *Turing model for natural language generation* to improve many tasks across Bing, Office, Dynamics, and other productivity products. For example:

* Microsoft Word users can now get answers to questions about document content. For example, if you’re looking at a biography of Alan Turing in Word, you can ask “where did he get his PhD?”
* Outlook users can reply to emails with the click of a button using AI-generated suggested replies.
* In SharePoint, users can see AI-generated document summaries by hovering over the file name, so they can find what they’re looking for faster.
* The Dynamics 365 Virtual Agent for Customer Service easily identifies and resolves common support issues using the Turing model.

These advances in Microsoft products help everyone be more productive, stay connected, and drive greater impact.

## Imagine what’s possible with AI at Scale and an AI-ready culture

As discussed in the module “Understand the importance of building an AI-ready culture,” taking full advantage of AI requires cultural shifts within an organization. When developing the Microsoft Turing models, we found it essential to have product teams collaborate and share data instead of working independently. Our progress wouldn't have been possible without shifting our approach from a siloed to a collaborative culture.

With our AI at Scale technology and an AI-ready culture, you can reach new heights in your AI journey. Later in this module, we'll dive deeper into how you can assign AI-related responsibilities in your organization.

Next, let’s hear more about AI at Scale from Luis Vargas, Partner Technical Advisor to the Microsoft CTO.
