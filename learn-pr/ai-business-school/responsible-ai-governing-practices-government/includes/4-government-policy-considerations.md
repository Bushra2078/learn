The promise of AI is that the knowledge gained from applying analytics and machine learning to the wealth of data that is available today enhances any decision-making process with more intelligence, leading to better outcomes and transforming lives. Recent research from McKinsey estimates that AI can boost global GDP by $13 trillion by 2030, which is about 16% cumulative growth or 1.2% extra GDP growth per year.<sup>4</sup> United Nations agencies have embraced AI as an accelerator for realizing the 2030 Sustainable Development Goals.

Beyond its potential benefits, AI has also raised concerns about economic disruptions and job displacements that could be caused by fast-paced automation. Technologies, including AI, are changing the nature of the workplace. How enterprises organize work, how people find work and the skills that people need to prepare for work are shifting. Gig or on-demand platforms enable companies to break work into tasks and to find people from anywhere in the world to perform these tasks, presenting enormous opportunities for workers and businesses.

As AI plays an increasing role in mediating peoples' lives online and offline, appropriate design, deployment, economic, and social choices are essential for the trust of individuals and society at large. The starting point for creating trust in AI is to take a human-centered approach, with system choices that are grounded in values shared by relevant stakeholders from industry, government, civil society, and the research community.

## An industry view on responsible AI

Microsoft shared our view of responsible AI in [The Future Computed: Artificial Intelligence and Its Role in Society](https://news.microsoft.com/futurecomputed/), identifying six principles to guide the cross-disciplinary development and use of AI technologies: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.<sup>5</sup>

Internally, Microsoft has created the AI and Ethics in Engineering & Research (Aether) Committee. This committee is a cross-company group that advises our Senior Leadership Team on rising questions, challenges, and opportunities with the development and fielding of AI and related technologies.

In September 2016, Microsoft co-founded the Partnership on AI (PAI) “to study and formulate best practices on AI technologies, to advance the public’s understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society.”<sup>6</sup> PAI now has more than 100 organizations (>50% are non-profits) from 13 countries/regions and 4 continents.

To encourage development of AI solutions to address global challenges, the Microsoft [AI for Good](https://www.microsoft.com/ai/ai-for-good) initiative is a $125 million, five-year commitment to encourage and support development of innovative AI solutions by organizations around the world. These organizations are working to address global challenges in accessibility, sustainability for the earth, humanitarian action, and the preservation of cultural heritage.

## Fostering trustworthy AI

Recognizing the economic transformation potential of AI, many governments have announced their national AI strategies. Global implementation of responsible AI received a boost in May 2019, when 36 OECD member countries, along with Argentina, Brazil, Colombia, Peru, and Romania, approved the Recommendations of the OECD Council on Artificial Intelligence. These recommendations contained the principles for responsible stewardship of trustworthy AI. These principles were also adopted by the G20 countries, including the EU, in June 2019.<sup>7</sup>

The recommendations, developed by an AI expert group that included representatives from academia, civil society, trade unions, business, and governments from around the world, clearly demonstrated the value of multistakeholder consultation in policy development. These recommendations are high-level principles, intended to foster trust and shape the continuing development of AI to be more trustworthy. They aren't prescriptive in ways that can restrict innovation.

As more countries/regions adopt the principles, it's hoped they'll lead to development of AI systems that warrant the trust of individuals and society, enabling broader adoption and realization of the transformative potential of AI. The OECD also included five recommendations on national policies and international cooperation for trustworthy AI.

The EU High Level Expert Group on AI also published its Ethics Guidelines on Artificial Intelligence in June 2019 and recommendations to update the joint coordinated plan on AI at the end of 2019.<sup>8</sup>

Both the OECD and EU are encouraging implementations of their proposed principles as the next step, with the goal of sharing best practices and comments based on those implementations.

## Responsible AI policy framework

As AI is still at a nascent stage of development, an open dialogue between government, business, civil society, and academic research is essential to shaping the continued development of the technology and realizing its potential benefits. Working together, governments can: identify and prioritize issues of societal importance, share best practices, motivate further research and development of solutions as new issues emerge, and facilitate a regulatory environment that fosters AI innovation.

Policy discussions should aim to promote broad development and use of AI systems that strive to uphold the OECD principles and address the issues raised in the EU guidelines. These activities should take place across different sectors and encourage outcomes that are aligned with the vision of human-centered AI.

### Considerations

* Continue to convene broad dialogues among government, business, researchers, civil society, and other interested stakeholders on how AI can be shaped to maximize its potential and mitigate its risks.
* Adopt practical guiding principles to increase awareness of and encourage development of trustworthy AI.
* Encourage sharing and promulgating of best practices in development and deployment of these technologies, especially at the sector level, leveraging industry-led organizations.
* Stimulate the development and deployment of AI across all sectors and businesses of all sizes, including the application of AI to public and societal challenges, such as empowering underserved communities and people with disabilities.
* Enable responsible data sharing and collaboration with an appropriate regulatory framework that is innovative but also preserves privacy, protects trade secrets, and encourages investment and market competition.
* Invest in skills development training initiatives for people at all stages of the job continuum, and provide appropriate social protection for workers in the new economy.
* Fund short- and long-term multidisciplinary research and development of responsible AI technologies and consider how AI can be used to provide insights into its potential socio-economic impact.  
* Develop shared public data sets and environments for AI training and testing, to enable broader experimentation and comparisons of alternative solutions to address ethical concerns with AI.

Human-centered AI can help create a better world, and it's important to continue working together to actively realize this future. An inclusive approach that values multidisciplinary and multistakeholder contributions and actions can motivate an open and collaborative model for policy development that can adapt to rapidly evolving technologies. It also facilitates development of more principle- and evidence-based policy frameworks, where desirable outcomes that are aligned with the vision of human-centered AI are encouraged.

## Integrated and holistically responsible AI policy frameworks

Any AI strategy would need to be an integral part of a holistic national agenda for digital transformation. For example, the OECD Going Digital project is a multidisciplinary project that aims to:

* Understand the digital transformation and its impacts on economy and society.
* Provide policymakers with the tools needed to develop a proactive whole-of-government policy response to help their economies prosper in an increasingly digital and data-driven world while advancing a culture of trust.
* Help overcome the often large gap between technology adoption and policy development.

The project spans multiple policy silos (for example: competition, consumer protection, education, employment, and trade) and recommends an integrated policy framework that consists of seven dimensions: access, use, innovation, jobs, society, trust, and market openness. Some elements that should be considered in such a framework that are essential to enabling AI include cloud deployment, cross border data access and flow, interoperable, open, and globally accessible internet, privacy, security, open government data, multistakeholder consultation and public-private partnerships.

Next, let’s hear from Susan Etlinger again on choosing an organizational model.

## References

[(4) McKinsey Global Institute, “Notes from the AI Frontier: Modeling the Impact of AI on the World Economy.” September 2018.](https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/Artificial%20Intelligence/Notes%20from%20the%20frontier%20Modeling%20the%20impact%20of%20AI%20on%20the%20world%20economy/MGI-Notes-from-the-AI-frontier-Modeling-the-impact-of-AI-on-the-world-economy-September-2018.ashx)  
[(5) Microsoft, “The Future Computed: Artificial Intelligence and its role in society.” Brad Smith and Harry Shum, 17 Jan 2018.](https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society/)  
[(6) Partnership on AI](https://www.partnershiponai.org/)  
[(7) OECD, “OECD Principles on AI.” May 2019.](https://www.oecd.org/going-digital/ai/principles/)  
[(8) European Commission, “Ethics Guidelines for Trustworthy Artificial Intelligence.” AI High Level Expert Group, 2019 June.](https://ec.europa.eu/futurium/en/blog/ethics-guidelines-trustworthy-artificial-intelligence-piloting-assessment-list.html)
