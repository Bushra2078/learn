The societal implications of AI and the responsibility of leaders to anticipate and mitigate unintended consequences of AI technology are significant. Considering this responsibility, governments are finding the need to establish governing practices to guide their AI efforts, whether they are deploying third-party AI solutions or developing their own. This is especially relevant in government scenarios that can affect a huge number of stakeholders.

Now that you have reviewed this module, you should be able to:

* Determine the elements of an AI governance system.
* Choose an AI governance model that fits your government’s needs.
* Approach policy discussions to promote broad development and deployment of ethical AI systems.

## Actions your organization can take

To help you consider how to leverage governance and external engagements in your own organization, we developed the recommendations below.

### Establishing an AI governance system

1. **Choose a governance structure** that best fits your organization’s AI maturity, unique characteristics, culture, and business objectives
1. **Outline the specific role of your governance system** within your organization. Responsibilities could include developing and enforcing policies, providing advice, and mitigating risks associated with AI systems.
1. **Allocate sufficient budget and resources** to give your governance system the power to enforce responsible AI policies.
1. **Adapt your governance system(s)** over time as your objectives and capabilities change.
1. **Train employees** on the policies, standards, and best practices that your governance system establishes.
1. **Engage in public and private partnerships** to advance the responsible use of AI. As the use of AI increases across the private and public sectors, it is essential that we continue to foster open dialogue among businesses, governments, NGOs (Non-Governmental Organizations), academic researchers, and all other interested individuals and organizations.
1. **Leverage lessons learned from internal AI deployments** to inform broader social policies or regulations related to AI.

### Additional tips for using third party AI systems

* Research the third party’s stance on responsible design before purchasing out-of-the-box AI solutions to ensure they were designed in a manner consistent with your principles, policies, and standards.
* Include your principles in your request for proposal so the solution can be designed with your principles in mind.
* Create guidelines on how to safely operate and monitor the system and train your employees on these guidelines before deploying the system.
* Rigorously test the system to ensure it operates as intended and in a manner consistent with your principles, policies, and standards.

### Additional tips for building first party AI systems

* **Consider having your governance system review or provide advice before the release of any new AI system**, especially for sensitive use cases.
* **Create processes for employees to analyze an AI system’s** purpose, technical capabilities, reliability, and use case prior to its release.
* **Provide clear guidelines to ensure your ethical principles are reflected in an AI system** if you are developing AI systems in-house. Support your developers by using industry-established guidelines or developing your own, especially for AI systems that raise complex ethical or human rights considerations.
* **Consider integrating internal guidelines into project management processes**, such as a checklist aligned to the phases of a data science project.
* **Leverage tools and resources** to make it easier for developers to spot and design against potentially harmful issues like biases, safety and privacy gaps, and exclusionary practices.

## Use these resources to discover more

[!include[](../../../includes/open-link-in-new-tab-note.md)]

To learn more about our perspective on responsible AI as well as the impact of AI on our future, read our book [The Future Computed](https://blogs.microsoft.com/uploads/2018/02/The-Future-Computed_2.8.18.pdf).

* [Download PDF](https://aka.ms/AA629xh) of Responsible AI in Government – Choosing a governance model to share with others.
* [Download PDF](https://aka.ms/AA62hpi) of Responsible AI in Government – Policy considerations to share with others.
* Understand your organization’s AI Maturity by taking Microsoft’s [AI Ready Assessment](https://info.microsoft.com/ww-landing-ai-maturity-model-website.html).
* Check out reports, podcasts, and training resources in the [AI in Government content hub](https://info.microsoft.com/ww-landing-AI-in-Government-Playlist.html) to learn more about how governments can leverage AI to lower costs while providing higher quality services to citizens.
* [To see how enterprises and other organizations are governing their use of responsible AI, review this module: Identify governing practices for responsible AI](https://docs.microsoft.com/learn/modules/responsible-ai-governing-practices/index).

## References

[(1) Financial Times, “How governments are beginning to regulate AI.” Madhumita Murgia and Siddarth Shrikanth, 29 May 2019.](https://www.ft.com/content/025315e8-7e4d-11e9-81d2-f785092ab560)