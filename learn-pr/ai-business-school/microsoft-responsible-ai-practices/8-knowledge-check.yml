### YamlMime:ModuleUnit
uid: learn-wwl.microsoft-responsible-ai-practices.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: A knowledge check for the identify governing practices for responsible AI in your organization module.
  ms.date: 10/01/2019
  author: RWortmanMorris
  ms.author: rawortma
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
durationInMinutes: 2
content: |
  [!include[](includes/8-knowledge-check.md)] 
quiz:
  title: Check your knowledge
  questions:
  - content: "Why is it important to monitor and maintain AI systems over time?"
    choices:
    - content: "Changes in model reliability can be detrimental to outcomes and put people’s safety at risk."
      isCorrect: true
      explanation: "Correct. If AI models become less reliable in industries like manufacturing or healthcare, people can get hurt."
    - content: "Changes in model reliability can lead to a freeze on a project’s funding."
      isCorrect: false
      explanation: "Incorrect. While it is true that funding may be pulled from an AI project due to diminished performance, losing funding is not primary the reason to carefully monitor and maintain an AI model."
    - content: "Changes in model reliability can hurt an organization’s ability to compete in the market."
      isCorrect: false
      explanation: "Incorrect. While it is true that diminished AI performance can allow competitors to get ahead, losing funding is not primary the reason to carefully monitor and maintain an AI model."
    - content: "Changes in model reliability can hurt an organization’s stock price."
      isCorrect: false
      explanation: "Incorrect. While it is true that diminished AI performance can be detrimental to an organization’s stock price, this is not primary the reason to carefully monitor and maintain an AI model."
  - content: "Why is it important to articulate how AI systems reach conclusions?"
    choices:
    - content: "By articulating how AI systems reach conclusions, organizations can eliminate bias from the AI’s decision-making process."
      isCorrect: false
      explanation: "Incorrect. Articulating how AI systems reach a conclusion will not eliminate bias, it can only identify it."
    - content: "Articulating how AI reaches conclusions helps people identify the sources of biases or exclusionary practices, safety and privacy concerns, or accuracy and reliability issues."
      isCorrect: true
      explanation: "Correct. The black-box nature of AI can be problematic and potentially harmful. For example, if an AI system is making decisions that impact people’s lives, stakeholders have a right to understand how that decision was reached. Articulating this process also builds trust."
    - content: "By articulating how AI systems reach conclusions, organizations can protect themselves from legal repercussions in cases where those decisions are allegedly biased."
      isCorrect: false
      explanation: "Incorrect. Articulating how AI systems reach conclusions does not clear organizations of their legal responsibilities."
    - content: "Organizations should not articulate how their AI systems reach conclusions because it exposes them to legal risk and possible IP theft."
      isCorrect: false
      explanation: "Incorrect. It is important for organizations to be able to articulate how their AI systems reach conclusions to identify the sources of biases or exclusionary practices, safety and privacy concerns, or accuracy and reliability issues."
  - content: "How can AI be used to address global climate issues in the agricultural industry?"
    choices:
    - content: "AI can be applied to data captured by drones and sensors to deliver actionable insight to farmers, increasing yield and reducing cost and environmental impact."
      isCorrect: true
      explanation: "Correct. For example, the FarmBeats project combined sensor data and aerial imagery to accelerate advances in agriculture."
    - content: "AI can predict water scarcity, enabling suppliers to increase prices at optimal times to maximize profit."
      isCorrect: false
      explanation: "Incorrect. While it is possible for AI to predict water scarcity, enabling suppliers to profit from water shortages does not address global climate issues."
    - content: "AI can predict weather patterns perfectly, increasing yields by allowing farmers to determine the best time to plant, fertilize, and harvest crops."
      isCorrect: false
      explanation: "Incorrect. While AI solutions can improve the accuracy of weather forecasts, perfection is unrealistic."
    - content: "AI-powered machinery will soon replace all humans in the agriculture industry, harvesting crops faster and at a higher volume."
      isCorrect: false
      explanation: "Incorrect. AI solutions can augment the human labor force and improve efficiency, but humans will always need to serve in an oversight role to AI."
  - content: "According to the Microsoft governance model, under what conditions would a sensitive use case be categorized as “infringement on human rights”?"
    choices:
    - content: "The scenario involves using AI in a way that could create a significant risk of physical harm to an individual."
      isCorrect: false
      explanation: "Incorrect. A scenario that creates a significant risk of physical harm to an individual would be categorized as a “risk of harm.”"
    - content: "The scenario involves using AI in a way that could possibly result in a significant restriction of personal freedom, speech, assembly, or privacy."
      isCorrect: true
      explanation: "Correct. Per the definition in responsible AI governance documentation at Microsoft, this scenario would be considered “infringement on human rights.”"
    - content: "The scenario involves the use of AI in a way that may directly result in the denial of consequential services or support to an individual."
      isCorrect: false
      explanation: "Incorrect. This scenario would be considered a “denial of consequential services,” in which AI could potentially be used to deny an individual access to financial, housing, insurance, education, recruiting, and healthcare services."
    - content: "The scenario involves using AI in a way that could create a significant risk of emotional harm to an individual would be categorized “infringe on human rights.”"
      isCorrect: false
      explanation: "Incorrect. A scenario that create a significant risk of emotional harm to an individual would be categorized as a “risk of harm.”"