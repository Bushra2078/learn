If you’re developing, implementing, or managing AI internally, you may want to consider how to honor your organization’s guiding principles at every step of the AI lifecycle. To empower technical employees to do so, we have found that it helps to translate your principles into actionable guidance.

Microsoft is on this journey as well, and we would like to share our perspective and experiences. For years, we have been working with other companies and institutions to help developers everywhere build and deploy AI responsibly. We also leverage open-source tools and look to leading organizations like Partnership on AI (PAI) for best practices, industry standards, and guidelines. By leveraging practical guidance, hopefully you and your team don’t have to develop your approach from scratch.

## Principles and guidelines

Microsoft’s responsible AI journey began when we established six key principles to guide our development and use of AI, which are outlined in a book we published in 2018, The Future Computed: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.<sup>3</sup> With these foundational principles in place, we began developing more scenario-specific guidelines.

For example, in May of 2019 we published a paper called Guidelines for Human-AI Interaction, which includes 18 generally applicable guidelines to help developers design responsible and human-centered AI systems.<sup>4</sup> These guidelines synthesize 150+ design recommendations from over 20 years of research in academia and industry. They suggest best practices for how AI systems should behave upon initial interaction, during regular interaction, when they’re inevitably wrong, and over time.

We’ve also released guidelines to help developers build responsible conversational AI.<sup>5</sup> Like any technology, virtual assistants and bots can pose a significant risk when developed and deployed improperly. This is especially true when they are helping people navigate information related to employment, finances, or health. We created these guidelines based on our own experiences, our research on responsible AI, and by listening to our customers and partners.

As for facial recognition technology, developers using our Azure Face API can leverage guidance we’ve published to help them better understand its capabilities and limitations, ways to influence accuracy, and the importance of considering how the system will be deployed and used.<sup>6</sup> We’ve also established six principles to govern the way we develop and deploy facial recognition at Microsoft, and we encourage other organizations to consider establishing guiding principles too.<sup>7</sup> While companies all bear responsibility for exercising responsibility in this area, we have called for increased legal regulation and governance to broadly mitigate the risks of misuse.<sup>8</sup>

These guidelines we have established will evolve over time as we at Microsoft continue to learn from our own experience and from the experiences of other tech companies, our customers, academics, civil society, and  multistakeholder organizations as well. For more information and links to these guidelines, see the summary and resources section of this module.

Next, let’s discuss innovative tools that help technical employees implement ethical principles from design and data collection to development and deployment.
