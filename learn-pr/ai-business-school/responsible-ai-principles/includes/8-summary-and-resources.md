Through this module we have walked through some of the steps Microsoft is taking to prioritize responsible AI in the hope that our experience can help others. However, we recognize that we do not have all the answers and every individual, company, and region will have their own beliefs and standards that should be reflected in their path towards responsible AI. We should also recognize that as organizations and as a society, our steps towards responsible AI will need to continually evolve to reflect new innovations and lessons from both our mistakes and accomplishments. The processes, tools, and resources mentioned can be a starting point from which organizations can create their own AI strategy.

As the use of AI increases across the private and public sectors, it is essential that we continue to foster open dialogue among businesses, governments, NGOs, academic researchers, and all other interested individuals and organizations. Those who embrace AI early have an important role to play in promoting the responsible use of AI and preparing society for its impacts. Their firsthand experience in dealing with the ethical challenges of AI will be crucial knowledge for later adopters and those trying to study or regulate AI technology.

Now that you have reviewed this module, you should be able to:

* Describe the importance of engaging with AI in a responsible manner.
* Identify six guiding principles to develop and use AI responsibly.

## Actions your organization can take

To help you consider how to implement these principles in your own organization, we developed the following recommendations:

### Fairness

* **Understand the scope, spirit, and potential uses of the AI system** by asking questions such as, how is the system intended to work? Who is the system designed to work for? Will it work for everyone equally? How can it harm others?
* **Attract a diverse pool of talent.** Ensure the design team reflects the world in which we live by including team members that have different backgrounds, experiences, education and perspectives.
* **Identify bias in datasets** by evaluating where the data came from, understanding how it was organized, and testing to ensure it is represented. Bias can be introduced at every stage in creation, from collection to modeling to operation.
* **Identify bias in machine learning algorithms** by leveraging tools and techniques that improve the transparency and intelligibility of models. Examples of these tools can be found in the next unit.
* **Leverage human review and domain expertise.** Train employees to understand the meaning and implications of AI results to ensure that they are ultimately accountable for decisions that leverage AI, especially when AI is used to inform consequential decisions about people. Finally, include relevant subject matter experts (such as those with consumer credit expertise for a credit scoring AI system) in the design process and in deployment decisions.
* **Research and employ best practices, analytical techniques, and tools** from other institutions and enterprises to help detect, prevent, and address bias in AI systems.

### Reliability and Safety

* **Understand your organization’s AI Maturity** by taking Microsoft’s AI Ready Assessment accessible from the link in the resources section. Use the results to determine which AI technologies will fit your organization’s current maturity level and how your organization can best take advantage of AI.
* **Develop processes for auditing AI systems** in order to evaluate the quality and suitability of data and models, monitor ongoing performance, and verify that systems are behaving as intended based on established performance measures.
* **Provide detailed explanation of system operation** including design specifications, information about training data, training failures that occurred and potential inadequacies with training data, and the inferences and significant predictions generated.
* **Design for unintended circumstances** such as accidental system interactions, the introduction of malicious data, or cyberattacks.
* **Involve domain experts in the design and implementation processes**, especially when AI is being used to help make consequential decisions about people.
* **Conduct rigorous testing during AI system development and deployment** to ensure that systems can respond safely to unanticipated circumstances, don’t have unexpected performance failures, and don’t evolve in unexpected ways. AI systems involved in high-stakes scenarios that affect human safety or large populations should be tested both in lab and real-world scenarios.
* **Evaluate when and how an AI system should seek human input for impactful decisions or during critical situations.** Consider how an AI system should transfer control to a human in a manner that is meaningful and intelligible. Design AI systems to ensure humans have the necessary level of input on highly impactful decisions.
* **Develop a robust feedback mechanism for users to report performance issues** so that they can be resolved quickly.

### Privacy and Security

* **Comply with relevant data protection, privacy, and transparency laws** like GDPR or the California Privacy Act by investing resources in developing compliance technologies and processes or working with a technology leader during the development of AI systems. Develop processes to continually check that the AI systems are satisfying all aspects of these laws.
* **Design AI systems to maintain the integrity of personal data** so that they can only use personal data during the time it’s required and for the defined purposes that have been shared with customers. Delete inadvertently collected personal data or data that is no longer relevant to the defined purpose.
* **Protect AI systems from bad actors** by designing AI systems in accordance with secure development and operations foundations, using role-based access, and protecting personal and confidential data that is transferred to third parties. Design AI systems to identify abnormal behaviors and to prevent manipulation and malicious attacks. Learn more about how to protect against new AI-specific security threats by reading our paper, Securing the Future of Artificial Intelligence and Machine Learning at Microsoft accessible in the resources section of this module.
* **Design AI systems with appropriate controls** for customers to make choices about how and why their data is collected and used.
* **Ensure your AI system maintains anonymity** by de-identifying personal data.
* **Conduct privacy and security reviews** for all AI systems.
* **Research and implement industry best practices** for tracking relevant information about customer data, accessing and using that data, and auditing access and use.

### Inclusiveness

* **Comply with laws regarding accessibility and inclusiveness** such as the Americans with Disabilities Act, the Communications and Video Accessibility Act, and the European Union laws and U.S. regulations that mandate the procurement of accessible technology.
* **Use the** Inclusive Design toolkit, available in the resources section of this module, to help system developers understand and address potential barriers in a product environment that could unintentionally exclude people.
* **Have people with disabilities test your systems** to help you determine whether the system can be used as intended by the broadest possible audience.
* **Consider commonly used accessibility standards** to help ensure your system is accessible for people of all abilities.

### Transparency

* **Share key characteristics of datasets** to help developers understand if a specific dataset is appropriate for their use case. For more information on tools and techniques for increasing transparency, please see the next unit, Governance and external engagements.
* **Improve model intelligibility** by leveraging simpler models and generating intelligible explanations of the model’s behavior. Techniques to simplify models without sacrificing accuracy and tools to generate explanations of model’s behaviors can be found in the next unit.
* **Train employees on how to interpret AI outputs** and ensure that they remain accountable for making consequential decisions based on the results.

### Accountability

* **Set up internal review boards** to provide oversight and guidance on the responsible development and deployment of AI systems.
* **Ensure your employees are trained** to use and maintain the solution in a responsible and ethical manner and understand when the solution may require additional technical support.
* **Keep humans with requisite expertise in the loop** by reporting to them and involving them in decisions about model execution. When automation of decisions is required, ensure they are able to inspect, identify, and resolve challenges with model output and execution.
* **Put in place a clear system of accountability and governance** to conduct remediation or correction activities if models are seen as behaving in an unfair or potentially harmful manner.

At Microsoft, we developed these six principles to guide our use of AI with the aim of respecting collective values while helping society realize the full potential of AI. We encourage organizations to do the same, by either creating or adapting existing principles or guidelines to fit with their culture and priorities.

## Use these resources to discover more

[!include[](../../../includes/open-link-in-new-tab-note.md)]

To learn more about our perspective on responsible AI as well as the impact of AI on our future, read our book [The Future Computed](https://blogs.microsoft.com/uploads/2018/02/The-Future-Computed_2.8.18.pdf).

* [Download PDF](https://aka.ms/AA62hp7) of Implications of responsible AI - Practical guide to share with others.
* [Download PDF](https://aka.ms/AA629xb) of Responsible AI - Identify guiding principles to share with others.
